{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64f4f004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: peft in ./.venv/lib/python3.12/site-packages (0.15.2)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.venv/lib/python3.12/site-packages (from peft) (2.3.1)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from peft) (24.2)\n",
      "Requirement already satisfied: psutil in ./.venv/lib/python3.12/site-packages (from peft) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in ./.venv/lib/python3.12/site-packages (from peft) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.13.0 in ./.venv/lib/python3.12/site-packages (from peft) (2.7.1)\n",
      "Requirement already satisfied: transformers in ./.venv/lib/python3.12/site-packages (from peft) (4.52.4)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.12/site-packages (from peft) (4.67.1)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in ./.venv/lib/python3.12/site-packages (from peft) (1.8.1)\n",
      "Requirement already satisfied: safetensors in ./.venv/lib/python3.12/site-packages (from peft) (0.5.3)\n",
      "Requirement already satisfied: huggingface_hub>=0.25.0 in ./.venv/lib/python3.12/site-packages (from peft) (0.33.1)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from huggingface_hub>=0.25.0->peft) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.12/site-packages (from huggingface_hub>=0.25.0->peft) (2025.3.0)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.12/site-packages (from huggingface_hub>=0.25.0->peft) (2.32.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.12/site-packages (from huggingface_hub>=0.25.0->peft) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in ./.venv/lib/python3.12/site-packages (from huggingface_hub>=0.25.0->peft) (1.1.5)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.12/site-packages (from torch>=1.13.0->peft) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.12/site-packages (from torch>=1.13.0->peft) (1.14.0)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.12/site-packages (from torch>=1.13.0->peft) (3.5)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.12/site-packages (from torch>=1.13.0->peft) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in ./.venv/lib/python3.12/site-packages (from torch>=1.13.0->peft) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in ./.venv/lib/python3.12/site-packages (from torch>=1.13.0->peft) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in ./.venv/lib/python3.12/site-packages (from torch>=1.13.0->peft) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in ./.venv/lib/python3.12/site-packages (from torch>=1.13.0->peft) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in ./.venv/lib/python3.12/site-packages (from torch>=1.13.0->peft) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in ./.venv/lib/python3.12/site-packages (from torch>=1.13.0->peft) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in ./.venv/lib/python3.12/site-packages (from torch>=1.13.0->peft) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in ./.venv/lib/python3.12/site-packages (from torch>=1.13.0->peft) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in ./.venv/lib/python3.12/site-packages (from torch>=1.13.0->peft) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in ./.venv/lib/python3.12/site-packages (from torch>=1.13.0->peft) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in ./.venv/lib/python3.12/site-packages (from torch>=1.13.0->peft) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in ./.venv/lib/python3.12/site-packages (from torch>=1.13.0->peft) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in ./.venv/lib/python3.12/site-packages (from torch>=1.13.0->peft) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in ./.venv/lib/python3.12/site-packages (from torch>=1.13.0->peft) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.1 in ./.venv/lib/python3.12/site-packages (from torch>=1.13.0->peft) (3.3.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.12/site-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests->huggingface_hub>=0.25.0->peft) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests->huggingface_hub>=0.25.0->peft) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests->huggingface_hub>=0.25.0->peft) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests->huggingface_hub>=0.25.0->peft) (2025.6.15)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.12/site-packages (from transformers->peft) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./.venv/lib/python3.12/site-packages (from transformers->peft) (0.21.2)\n",
      "Requirement already satisfied: accelerate in ./.venv/lib/python3.12/site-packages (1.8.1)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in ./.venv/lib/python3.12/site-packages (from accelerate) (2.3.1)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from accelerate) (24.2)\n",
      "Requirement already satisfied: psutil in ./.venv/lib/python3.12/site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in ./.venv/lib/python3.12/site-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in ./.venv/lib/python3.12/site-packages (from accelerate) (2.7.1)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in ./.venv/lib/python3.12/site-packages (from accelerate) (0.33.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./.venv/lib/python3.12/site-packages (from accelerate) (0.5.3)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from huggingface_hub>=0.21.0->accelerate) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.12/site-packages (from huggingface_hub>=0.21.0->accelerate) (2025.3.0)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.12/site-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in ./.venv/lib/python3.12/site-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.12/site-packages (from huggingface_hub>=0.21.0->accelerate) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in ./.venv/lib/python3.12/site-packages (from huggingface_hub>=0.21.0->accelerate) (1.1.5)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.5)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in ./.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in ./.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in ./.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in ./.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in ./.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in ./.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in ./.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in ./.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in ./.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in ./.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in ./.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in ./.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in ./.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in ./.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.1 in ./.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.3.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.12/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.6.15)\n",
      "Requirement already satisfied: bitsandBytes in ./.venv/lib/python3.12/site-packages (0.46.0)\n",
      "Requirement already satisfied: torch<3,>=2.2 in ./.venv/lib/python3.12/site-packages (from bitsandBytes) (2.7.1)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.venv/lib/python3.12/site-packages (from bitsandBytes) (2.3.1)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from torch<3,>=2.2->bitsandBytes) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.12/site-packages (from torch<3,>=2.2->bitsandBytes) (4.14.0)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.12/site-packages (from torch<3,>=2.2->bitsandBytes) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.12/site-packages (from torch<3,>=2.2->bitsandBytes) (1.14.0)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.12/site-packages (from torch<3,>=2.2->bitsandBytes) (3.5)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.12/site-packages (from torch<3,>=2.2->bitsandBytes) (3.1.6)\n",
      "Requirement already satisfied: fsspec in ./.venv/lib/python3.12/site-packages (from torch<3,>=2.2->bitsandBytes) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in ./.venv/lib/python3.12/site-packages (from torch<3,>=2.2->bitsandBytes) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in ./.venv/lib/python3.12/site-packages (from torch<3,>=2.2->bitsandBytes) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in ./.venv/lib/python3.12/site-packages (from torch<3,>=2.2->bitsandBytes) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in ./.venv/lib/python3.12/site-packages (from torch<3,>=2.2->bitsandBytes) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in ./.venv/lib/python3.12/site-packages (from torch<3,>=2.2->bitsandBytes) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in ./.venv/lib/python3.12/site-packages (from torch<3,>=2.2->bitsandBytes) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in ./.venv/lib/python3.12/site-packages (from torch<3,>=2.2->bitsandBytes) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in ./.venv/lib/python3.12/site-packages (from torch<3,>=2.2->bitsandBytes) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in ./.venv/lib/python3.12/site-packages (from torch<3,>=2.2->bitsandBytes) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in ./.venv/lib/python3.12/site-packages (from torch<3,>=2.2->bitsandBytes) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in ./.venv/lib/python3.12/site-packages (from torch<3,>=2.2->bitsandBytes) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in ./.venv/lib/python3.12/site-packages (from torch<3,>=2.2->bitsandBytes) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in ./.venv/lib/python3.12/site-packages (from torch<3,>=2.2->bitsandBytes) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in ./.venv/lib/python3.12/site-packages (from torch<3,>=2.2->bitsandBytes) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.1 in ./.venv/lib/python3.12/site-packages (from torch<3,>=2.2->bitsandBytes) (3.3.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch<3,>=2.2->bitsandBytes) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.12/site-packages (from jinja2->torch<3,>=2.2->bitsandBytes) (3.0.2)\n",
      "Requirement already satisfied: transformers in ./.venv/lib/python3.12/site-packages (4.52.4)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in ./.venv/lib/python3.12/site-packages (from transformers) (0.33.1)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.venv/lib/python3.12/site-packages (from transformers) (2.3.1)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.12/site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./.venv/lib/python3.12/site-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./.venv/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./.venv/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in ./.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests->transformers) (2025.6.15)\n",
      "Requirement already satisfied: datasets in ./.venv/lib/python3.12/site-packages (3.6.0)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.venv/lib/python3.12/site-packages (from datasets) (2.3.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in ./.venv/lib/python3.12/site-packages (from datasets) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./.venv/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.12/site-packages (from datasets) (2.3.0)\n",
      "Requirement already satisfied: requests>=2.32.2 in ./.venv/lib/python3.12/site-packages (from datasets) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in ./.venv/lib/python3.12/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in ./.venv/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in ./.venv/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in ./.venv/lib/python3.12/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in ./.venv/lib/python3.12/site-packages (from datasets) (0.33.1)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.12/site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.12/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in ./.venv/lib/python3.12/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.13)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.5.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.0 in ./.venv/lib/python3.12/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.12/site-packages (from huggingface-hub>=0.24.0->datasets) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in ./.venv/lib/python3.12/site-packages (from huggingface-hub>=0.24.0->datasets) (1.1.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2025.6.15)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install peft\n",
    "!pip install accelerate\n",
    "!pip install bitsandBytes\n",
    "!pip install transformers\n",
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a64960b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: GPUtil in ./.venv/lib/python3.12/site-packages (1.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install GPUtil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a437429f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 30% | 56% |\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import GPUtil\n",
    "import os\n",
    "\n",
    "GPUtil.showUtilization()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU is not available, using CPU instead\")\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "456ed05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, LlamaTokenizer\n",
    "from huggingface_hub import notebook_login\n",
    "from datasets import load_dataset\n",
    "from peft import prepare_model_for_kbit_training, LoraConfig, get_peft_model\n",
    "\n",
    "if \"COLAB_GPU\" in os.environ:\n",
    "  from google.colab import output\n",
    "  output.enable_custom_widget_manager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0cd4f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in ./.venv/lib/python3.12/site-packages (8.1.7)\n",
      "Requirement already satisfied: comm>=0.1.3 in ./.venv/lib/python3.12/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in ./.venv/lib/python3.12/site-packages (from ipywidgets) (9.3.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in ./.venv/lib/python3.12/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in ./.venv/lib/python3.12/site-packages (from ipywidgets) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in ./.venv/lib/python3.12/site-packages (from ipywidgets) (3.0.15)\n",
      "Requirement already satisfied: decorator in ./.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in ./.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in ./.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in ./.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in ./.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in ./.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
      "Requirement already satisfied: stack_data in ./.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in ./.venv/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in ./.venv/lib/python3.12/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./.venv/lib/python3.12/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./.venv/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./.venv/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in ./.venv/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21086fda79834fd4b8e3a5df72f42953",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if \"COLAB_GPU\" in os.environ:\n",
    "    !huggingface-cli login\n",
    "else:\n",
    "    %pip install ipywidgets\n",
    "    from huggingface_hub import notebook_login\n",
    "    notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31a07705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available. Loading model with quantization.\n",
      "Model loaded on device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, LlamaTokenizer\n",
    "from huggingface_hub import notebook_login\n",
    "from datasets import load_dataset\n",
    "from peft import prepare_model_for_kbit_training, LoraConfig, get_peft_model\n",
    "import os # Import os\n",
    "\n",
    "if \"COLAB_GPU\" in os.environ:\n",
    "  from google.colab import output\n",
    "  output.enable_custom_widget_manager()\n",
    "\n",
    "base_model_id = \"meta-llama/Llama-3.2-1B\"\n",
    "\n",
    "# Check if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available. Loading model with quantization.\")\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16\n",
    "    )\n",
    "    model = AutoModelForCausalLM.from_pretrained(base_model_id, quantization_config=bnb_config)\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    print(\"GPU is not available. Loading model without quantization (on CPU).\")\n",
    "    # Load model without quantization config\n",
    "    model = AutoModelForCausalLM.from_pretrained(base_model_id)\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Model loaded on device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b617046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'context' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/Rajangupta9/context.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c16a2d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "🚀 DIRECT JSON TO DATASET CONVERSION\n",
      "======================================================================\n",
      "\n",
      "1️⃣ LOADING OUTPUT.JSON\n",
      "----------------------------------------\n",
      "📂 Loading output directly from JSON...\n",
      "   ✅ JSON loaded: 8 records\n",
      "   ✅ Dataset created successfully!\n",
      "   📊 Number of examples: 8\n",
      "   🏗️  Features: ['component', 'card_background', 'card_enable', 'card_open', '_id', 'pr_img', 'name', 'name_config', 'desc', 'desc_config', 'company', 'contact_shortcut_enable', 'enable_pr', 'contact_shortcuts', 'show_brand_img', 'enable_br', 'br_img']\n",
      "\n",
      "2️⃣ LOADING TEMPLATE.JSON\n",
      "----------------------------------------\n",
      "📂 Loading template directly from JSON...\n",
      "   ✅ JSON loaded: 1 records\n",
      "   ✅ Dataset created successfully!\n",
      "   📊 Number of examples: 1\n",
      "   🏗️  Features: ['template_id', 'qr_codes']\n",
      "\n",
      "======================================================================\n",
      "📊 DETAILED DATASET INFORMATION\n",
      "======================================================================\n",
      "\n",
      "📋 OUTPUT DATASET INFO:\n",
      "   📊 Total examples: 8\n",
      "   🏗️  Features (17):\n",
      "      • component: Value(dtype='string', id=None)\n",
      "      • card_background: Value(dtype='int64', id=None)\n",
      "      • card_enable: Value(dtype='int64', id=None)\n",
      "      • card_open: Value(dtype='int64', id=None)\n",
      "      • _id: Value(dtype='string', id=None)\n",
      "      • pr_img: Value(dtype='string', id=None)\n",
      "      • name: Value(dtype='string', id=None)\n",
      "      • name_config: {}\n",
      "      • desc: Value(dtype='string', id=None)\n",
      "      • desc_config: {'align': Value(dtype='string', id=None), 'bold': Value(dtype='int64', id=None), 'italic': Value(dtype='int64', id=None), 'lock': Value(dtype='string', id=None)}\n",
      "      • company: Value(dtype='string', id=None)\n",
      "      • contact_shortcut_enable: Value(dtype='int64', id=None)\n",
      "      • enable_pr: Value(dtype='int64', id=None)\n",
      "      • contact_shortcuts: [{'_id': Value(dtype='string', id=None), 'type': Value(dtype='string', id=None), 'type_config': {}, 'value': Value(dtype='string', id=None), 'value_config': {}}]\n",
      "      • show_brand_img: Value(dtype='int64', id=None)\n",
      "      • enable_br: Value(dtype='int64', id=None)\n",
      "      • br_img: Value(dtype='string', id=None)\n",
      "\n",
      "   📝 SAMPLE DATA (First Example):\n",
      "      • component: profile\n",
      "      • card_background: 0\n",
      "      • card_enable: 1\n",
      "      • card_open: 1\n",
      "      • _id: uFpMGYHp1750825849079H\n",
      "      • pr_img: https://www.qrcodechimp.com/images/digitalCard/...\n",
      "      • name: Rajan \n",
      "      • name_config: Dict with 0 keys\n",
      "      • desc: Mr\n",
      "      • desc_config: Dict with 4 keys\n",
      "        └─ Keys: ['align', 'bold', 'italic']...\n",
      "      • company: Tez Minds\n",
      "      • contact_shortcut_enable: 1\n",
      "      • enable_pr: 1\n",
      "      • contact_shortcuts: List with 3 items\n",
      "        └─ First item type: <class 'dict'>\n",
      "        └─ Sample keys: ['_id', 'type', 'type_config']...\n",
      "      • show_brand_img: 1\n",
      "      • enable_br: 1\n",
      "      • br_img: https://www.qrcodechimp.com/images/digitalCard/...\n",
      "\n",
      "🔍 NESTED STRUCTURE ANALYSIS - OUTPUT:\n",
      "\n",
      "   📋 desc_config (Dict):\n",
      "      • align: NoneType\n",
      "      • bold: NoneType\n",
      "      • italic: NoneType\n",
      "      • lock: NoneType\n",
      "\n",
      "   📋 contact_shortcuts (List):\n",
      "      └─ Length: 3\n",
      "      └─ Item structure (first item):\n",
      "         • _id: str\n",
      "         • type: str\n",
      "         • type_config: dict\n",
      "         • value: str\n",
      "         • value_config: dict\n",
      "\n",
      "📋 TEMPLATE DATASET INFO:\n",
      "   📊 Total examples: 1\n",
      "   🏗️  Features (2):\n",
      "      • template_id: Value(dtype='string', id=None)\n",
      "      • qr_codes: [{'content': [{'appointments': [{'label': Value(dtype='string', id=None), 'link': Value(dtype='string', id=None)}], 'br_img': Value(dtype='string', id=None), 'card_delete_disabled': Value(dtype='int64', id=None), 'card_desc': Value(dtype='string', id=None), 'card_label': Value(dtype='string', id=None), 'company': Value(dtype='string', id=None), 'component': Value(dtype='string', id=None), 'contact_infos': [{'action_button_label': Value(dtype='string', id=None), 'action_button_link': Value(dtype='string', id=None), 'city': Value(dtype='string', id=None), 'country': Value(dtype='string', id=None), 'email': Value(dtype='string', id=None), 'label': Value(dtype='string', id=None), 'number': Value(dtype='string', id=None), 'state': Value(dtype='string', id=None), 'street': Value(dtype='string', id=None), 'title': Value(dtype='string', id=None), 'type': Value(dtype='string', id=None), 'zip': Value(dtype='string', id=None)}], 'contact_shortcuts': [{'type': Value(dtype='string', id=None), 'value': Value(dtype='string', id=None)}], 'contact_title': Value(dtype='string', id=None), 'desc': Value(dtype='string', id=None), 'desc_config': {'align': Value(dtype='string', id=None), 'bold': Value(dtype='int64', id=None), 'italic': Value(dtype='int64', id=None), 'lock': Value(dtype='string', id=None)}, 'ebusiness_card_enable': Value(dtype='int64', id=None), 'floating_button_label': Value(dtype='string', id=None), 'form_config': [{'button_label': Value(dtype='string', id=None), 'enable_header_img': Value(dtype='int64', id=None), 'form_fields': [{'_id': Value(dtype='string', id=None), 'label': Value(dtype='string', id=None), 'required': Value(dtype='bool', id=None), 'type': Value(dtype='string', id=None)}], 'header': {'desc': Value(dtype='string', id=None), 'header_enable': Value(dtype='int64', id=None), 'title': Value(dtype='string', id=None)}, 'header_img': Value(dtype='string', id=None), 'terms_label': Value(dtype='string', id=None)}], 'form_integration': Sequence(feature=Value(dtype='null', id=None), length=-1, id=None), 'form_name': Value(dtype='string', id=None), 'icon_img': Value(dtype='string', id=None), 'images': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'links': [{'icon_img': Value(dtype='string', id=None), 'subtitle': Value(dtype='string', id=None), 'title': Value(dtype='string', id=None), 'type': Value(dtype='string', id=None), 'url': Value(dtype='string', id=None)}], 'name': Value(dtype='string', id=None), 'pr_img': Value(dtype='string', id=None), 'title': Value(dtype='string', id=None), 'title_config': {'align': Value(dtype='string', id=None), 'bold': Value(dtype='int64', id=None), 'italic': Value(dtype='int64', id=None), 'lock': Value(dtype='string', id=None)}, 'view_config': {'delay_time': Value(dtype='string', id=None), 'dismiss_form': Value(dtype='int64', id=None), 'form_trigger': Value(dtype='string', id=None), 'form_view': Value(dtype='string', id=None), 'view_type': Value(dtype='string', id=None)}, 'view_type': Value(dtype='string', id=None)}], 'qr_name': Value(dtype='string', id=None), 'short_url': Value(dtype='string', id=None)}]\n",
      "\n",
      "   📝 SAMPLE DATA (First Example):\n",
      "      • template_id: b_685bb94064ea9b78d567cade\n",
      "      • qr_codes: List with 1 items\n",
      "        └─ First item type: <class 'dict'>\n",
      "        └─ Sample keys: ['content', 'qr_name', 'short_url']\n",
      "\n",
      "🔍 NESTED STRUCTURE ANALYSIS - TEMPLATE:\n",
      "\n",
      "   📋 qr_codes (List):\n",
      "      └─ Length: 1\n",
      "      └─ Item structure (first item):\n",
      "         • content: list\n",
      "         • qr_name: str\n",
      "         • short_url: str\n",
      "\n",
      "======================================================================\n",
      "🎯 FINAL SUMMARY\n",
      "======================================================================\n",
      "✅ OUTPUT DATASET: Successfully loaded with 8 examples\n",
      "✅ TEMPLATE DATASET: Successfully loaded with 1 examples\n",
      "\n",
      "🎉 SUCCESS! Both datasets are ready for use!\n",
      "\n",
      "💡 Next steps:\n",
      "   • Use output_dataset for component analysis\n",
      "   • Use template_dataset for template structure analysis\n",
      "   • Both datasets support all HuggingFace Dataset operations\n",
      "   • You can now proceed with your machine learning tasks!\n",
      "\n",
      "🔧 Example operations you can now perform:\n",
      "   • output_dataset.filter(lambda x: x['component'] == 'profile')\n",
      "   • output_dataset.map(lambda x: {...})\n",
      "   • output_dataset.select(range(5))  # Get first 5 examples\n",
      "   • output_dataset.to_pandas()  # Convert to pandas DataFrame\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, Features, Value, Sequence\n",
    "import json\n",
    "import tempfile\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "def load_json_as_dataset(file_path, dataset_name=\"dataset\"):\n",
    "    \"\"\"Load JSON file directly and convert to HuggingFace Dataset\"\"\"\n",
    "    try:\n",
    "        print(f\"📂 Loading {dataset_name} directly from JSON...\")\n",
    "        \n",
    "        # Read JSON file\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        print(f\"   ✅ JSON loaded: {len(data)} records\")\n",
    "        \n",
    "        # Create temporary directory for this specific dataset\n",
    "        temp_dir = tempfile.mkdtemp(prefix=f\"dataset_{dataset_name}_\")\n",
    "        \n",
    "        try:\n",
    "            # Create Dataset directly from the loaded data\n",
    "            dataset = Dataset.from_list(data)\n",
    "            print(f\"   ✅ Dataset created successfully!\")\n",
    "            print(f\"   📊 Number of examples: {len(dataset)}\")\n",
    "            print(f\"   🏗️  Features: {list(dataset.features.keys())}\")\n",
    "            \n",
    "            return dataset, None\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ Error creating dataset: {str(e)}\")\n",
    "            return None, str(e)\n",
    "        finally:\n",
    "            # Clean up temporary directory\n",
    "            try:\n",
    "                shutil.rmtree(temp_dir)\n",
    "            except:\n",
    "                pass\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"   ❌ Error loading JSON: {str(e)}\")\n",
    "        return None, str(e)\n",
    "\n",
    "def display_dataset_info(dataset, dataset_name):\n",
    "    \"\"\"Display comprehensive information about the dataset\"\"\"\n",
    "    if dataset is None:\n",
    "        print(f\"❌ {dataset_name} is None\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\n📋 {dataset_name.upper()} DATASET INFO:\")\n",
    "    print(f\"   📊 Total examples: {len(dataset)}\")\n",
    "    print(f\"   🏗️  Features ({len(dataset.features)}):\")\n",
    "    \n",
    "    for feature_name, feature_type in dataset.features.items():\n",
    "        print(f\"      • {feature_name}: {feature_type}\")\n",
    "    \n",
    "    # Show first example\n",
    "    if len(dataset) > 0:\n",
    "        print(f\"\\n   📝 SAMPLE DATA (First Example):\")\n",
    "        example = dataset[0]\n",
    "        for key, value in example.items():\n",
    "            if isinstance(value, (list, dict)):\n",
    "                if isinstance(value, list):\n",
    "                    print(f\"      • {key}: List with {len(value)} items\")\n",
    "                    if len(value) > 0:\n",
    "                        print(f\"        └─ First item type: {type(value[0])}\")\n",
    "                        if isinstance(value[0], dict) and len(value[0]) > 0:\n",
    "                            first_keys = list(value[0].keys())[:3]\n",
    "                            print(f\"        └─ Sample keys: {first_keys}{'...' if len(value[0]) > 3 else ''}\")\n",
    "                else:\n",
    "                    print(f\"      • {key}: Dict with {len(value)} keys\")\n",
    "                    if len(value) > 0:\n",
    "                        sample_keys = list(value.keys())[:3]\n",
    "                        print(f\"        └─ Keys: {sample_keys}{'...' if len(value) > 3 else ''}\")\n",
    "            else:\n",
    "                # Truncate long strings for display\n",
    "                str_value = str(value)\n",
    "                if len(str_value) > 50:\n",
    "                    str_value = str_value[:47] + \"...\"\n",
    "                print(f\"      • {key}: {str_value}\")\n",
    "\n",
    "def analyze_nested_structure(dataset, dataset_name):\n",
    "    \"\"\"Analyze nested structures in the dataset\"\"\"\n",
    "    if dataset is None or len(dataset) == 0:\n",
    "        return\n",
    "    \n",
    "    print(f\"\\n🔍 NESTED STRUCTURE ANALYSIS - {dataset_name.upper()}:\")\n",
    "    \n",
    "    example = dataset[0]\n",
    "    for key, value in example.items():\n",
    "        if isinstance(value, list) and len(value) > 0:\n",
    "            print(f\"\\n   📋 {key} (List):\")\n",
    "            print(f\"      └─ Length: {len(value)}\")\n",
    "            \n",
    "            if isinstance(value[0], dict):\n",
    "                print(f\"      └─ Item structure (first item):\")\n",
    "                for sub_key, sub_value in value[0].items():\n",
    "                    print(f\"         • {sub_key}: {type(sub_value).__name__}\")\n",
    "                    \n",
    "        elif isinstance(value, dict) and len(value) > 0:\n",
    "            print(f\"\\n   📋 {key} (Dict):\")\n",
    "            for sub_key, sub_value in value.items():\n",
    "                print(f\"      • {sub_key}: {type(sub_value).__name__}\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"🚀 DIRECT JSON TO DATASET CONVERSION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Load both datasets directly\n",
    "print(\"\\n1️⃣ LOADING OUTPUT.JSON\")\n",
    "print(\"-\" * 40)\n",
    "output_dataset, output_error = load_json_as_dataset(\"context/output.json\", \"output\")\n",
    "\n",
    "print(\"\\n2️⃣ LOADING TEMPLATE.JSON\")\n",
    "print(\"-\" * 40)\n",
    "template_dataset, template_error = load_json_as_dataset(\"context/template.json\", \"template\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"📊 DETAILED DATASET INFORMATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Display detailed information for both datasets\n",
    "if output_dataset:\n",
    "    display_dataset_info(output_dataset, \"output\")\n",
    "    analyze_nested_structure(output_dataset, \"output\")\n",
    "\n",
    "if template_dataset:\n",
    "    display_dataset_info(template_dataset, \"template\")\n",
    "    analyze_nested_structure(template_dataset, \"template\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"🎯 FINAL SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "success_count = 0\n",
    "if output_dataset:\n",
    "    print(f\"✅ OUTPUT DATASET: Successfully loaded with {len(output_dataset)} examples\")\n",
    "    success_count += 1\n",
    "else:\n",
    "    print(f\"❌ OUTPUT DATASET: Failed to load - {output_error}\")\n",
    "\n",
    "if template_dataset:\n",
    "    print(f\"✅ TEMPLATE DATASET: Successfully loaded with {len(template_dataset)} examples\")\n",
    "    success_count += 1\n",
    "else:\n",
    "    print(f\"❌ TEMPLATE DATASET: Failed to load - {template_error}\")\n",
    "\n",
    "if success_count == 2:\n",
    "    print(f\"\\n🎉 SUCCESS! Both datasets are ready for use!\")\n",
    "    print(f\"\\n💡 Next steps:\")\n",
    "    print(f\"   • Use output_dataset for component analysis\")\n",
    "    print(f\"   • Use template_dataset for template structure analysis\")\n",
    "    print(f\"   • Both datasets support all HuggingFace Dataset operations\")\n",
    "    print(f\"   • You can now proceed with your machine learning tasks!\")\n",
    "    \n",
    "    # Show some example operations you can perform\n",
    "    print(f\"\\n🔧 Example operations you can now perform:\")\n",
    "    print(f\"   • output_dataset.filter(lambda x: x['component'] == 'profile')\")\n",
    "    print(f\"   • output_dataset.map(lambda x: {{...}})\")\n",
    "    print(f\"   • output_dataset.select(range(5))  # Get first 5 examples\")\n",
    "    print(f\"   • output_dataset.to_pandas()  # Convert to pandas DataFrame\")\n",
    "    \n",
    "elif success_count == 1:\n",
    "    print(f\"\\n⚠️  PARTIAL SUCCESS: One dataset loaded successfully\")\n",
    "else:\n",
    "    print(f\"\\n❌ FAILURE: Neither dataset could be loaded\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f537c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PreTrainedTokenizerFast(name_or_path='meta-llama/Llama-3.2-1B', vocab_size=128000, model_max_length=131072, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|begin_of_text|>', 'eos_token': '<|end_of_text|>', 'pad_token': '<|end_of_text|>'}, clean_up_tokenization_spaces=True, added_tokens_decoder={\n",
      "\t128000: AddedToken(\"<|begin_of_text|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128001: AddedToken(\"<|end_of_text|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128002: AddedToken(\"<|reserved_special_token_0|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128003: AddedToken(\"<|reserved_special_token_1|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128004: AddedToken(\"<|finetune_right_pad_id|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128005: AddedToken(\"<|reserved_special_token_2|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128006: AddedToken(\"<|start_header_id|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128007: AddedToken(\"<|end_header_id|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128008: AddedToken(\"<|eom_id|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128009: AddedToken(\"<|eot_id|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128010: AddedToken(\"<|python_tag|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128011: AddedToken(\"<|reserved_special_token_3|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128012: AddedToken(\"<|reserved_special_token_4|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128013: AddedToken(\"<|reserved_special_token_5|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128014: AddedToken(\"<|reserved_special_token_6|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128015: AddedToken(\"<|reserved_special_token_7|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128016: AddedToken(\"<|reserved_special_token_8|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128017: AddedToken(\"<|reserved_special_token_9|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128018: AddedToken(\"<|reserved_special_token_10|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128019: AddedToken(\"<|reserved_special_token_11|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128020: AddedToken(\"<|reserved_special_token_12|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128021: AddedToken(\"<|reserved_special_token_13|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128022: AddedToken(\"<|reserved_special_token_14|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128023: AddedToken(\"<|reserved_special_token_15|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128024: AddedToken(\"<|reserved_special_token_16|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128025: AddedToken(\"<|reserved_special_token_17|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128026: AddedToken(\"<|reserved_special_token_18|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128027: AddedToken(\"<|reserved_special_token_19|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128028: AddedToken(\"<|reserved_special_token_20|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128029: AddedToken(\"<|reserved_special_token_21|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128030: AddedToken(\"<|reserved_special_token_22|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128031: AddedToken(\"<|reserved_special_token_23|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128032: AddedToken(\"<|reserved_special_token_24|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128033: AddedToken(\"<|reserved_special_token_25|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128034: AddedToken(\"<|reserved_special_token_26|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128035: AddedToken(\"<|reserved_special_token_27|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128036: AddedToken(\"<|reserved_special_token_28|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128037: AddedToken(\"<|reserved_special_token_29|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128038: AddedToken(\"<|reserved_special_token_30|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128039: AddedToken(\"<|reserved_special_token_31|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128040: AddedToken(\"<|reserved_special_token_32|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128041: AddedToken(\"<|reserved_special_token_33|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128042: AddedToken(\"<|reserved_special_token_34|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128043: AddedToken(\"<|reserved_special_token_35|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128044: AddedToken(\"<|reserved_special_token_36|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128045: AddedToken(\"<|reserved_special_token_37|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128046: AddedToken(\"<|reserved_special_token_38|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128047: AddedToken(\"<|reserved_special_token_39|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128048: AddedToken(\"<|reserved_special_token_40|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128049: AddedToken(\"<|reserved_special_token_41|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128050: AddedToken(\"<|reserved_special_token_42|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128051: AddedToken(\"<|reserved_special_token_43|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128052: AddedToken(\"<|reserved_special_token_44|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128053: AddedToken(\"<|reserved_special_token_45|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128054: AddedToken(\"<|reserved_special_token_46|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128055: AddedToken(\"<|reserved_special_token_47|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128056: AddedToken(\"<|reserved_special_token_48|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128057: AddedToken(\"<|reserved_special_token_49|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128058: AddedToken(\"<|reserved_special_token_50|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128059: AddedToken(\"<|reserved_special_token_51|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128060: AddedToken(\"<|reserved_special_token_52|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128061: AddedToken(\"<|reserved_special_token_53|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128062: AddedToken(\"<|reserved_special_token_54|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128063: AddedToken(\"<|reserved_special_token_55|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128064: AddedToken(\"<|reserved_special_token_56|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128065: AddedToken(\"<|reserved_special_token_57|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128066: AddedToken(\"<|reserved_special_token_58|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128067: AddedToken(\"<|reserved_special_token_59|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128068: AddedToken(\"<|reserved_special_token_60|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128069: AddedToken(\"<|reserved_special_token_61|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128070: AddedToken(\"<|reserved_special_token_62|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128071: AddedToken(\"<|reserved_special_token_63|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128072: AddedToken(\"<|reserved_special_token_64|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128073: AddedToken(\"<|reserved_special_token_65|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128074: AddedToken(\"<|reserved_special_token_66|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128075: AddedToken(\"<|reserved_special_token_67|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128076: AddedToken(\"<|reserved_special_token_68|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128077: AddedToken(\"<|reserved_special_token_69|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128078: AddedToken(\"<|reserved_special_token_70|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128079: AddedToken(\"<|reserved_special_token_71|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128080: AddedToken(\"<|reserved_special_token_72|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128081: AddedToken(\"<|reserved_special_token_73|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128082: AddedToken(\"<|reserved_special_token_74|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128083: AddedToken(\"<|reserved_special_token_75|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128084: AddedToken(\"<|reserved_special_token_76|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128085: AddedToken(\"<|reserved_special_token_77|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128086: AddedToken(\"<|reserved_special_token_78|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128087: AddedToken(\"<|reserved_special_token_79|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128088: AddedToken(\"<|reserved_special_token_80|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128089: AddedToken(\"<|reserved_special_token_81|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128090: AddedToken(\"<|reserved_special_token_82|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128091: AddedToken(\"<|reserved_special_token_83|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128092: AddedToken(\"<|reserved_special_token_84|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128093: AddedToken(\"<|reserved_special_token_85|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128094: AddedToken(\"<|reserved_special_token_86|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128095: AddedToken(\"<|reserved_special_token_87|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128096: AddedToken(\"<|reserved_special_token_88|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128097: AddedToken(\"<|reserved_special_token_89|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128098: AddedToken(\"<|reserved_special_token_90|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128099: AddedToken(\"<|reserved_special_token_91|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128100: AddedToken(\"<|reserved_special_token_92|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128101: AddedToken(\"<|reserved_special_token_93|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128102: AddedToken(\"<|reserved_special_token_94|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128103: AddedToken(\"<|reserved_special_token_95|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128104: AddedToken(\"<|reserved_special_token_96|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128105: AddedToken(\"<|reserved_special_token_97|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128106: AddedToken(\"<|reserved_special_token_98|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128107: AddedToken(\"<|reserved_special_token_99|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128108: AddedToken(\"<|reserved_special_token_100|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128109: AddedToken(\"<|reserved_special_token_101|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128110: AddedToken(\"<|reserved_special_token_102|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128111: AddedToken(\"<|reserved_special_token_103|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128112: AddedToken(\"<|reserved_special_token_104|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128113: AddedToken(\"<|reserved_special_token_105|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128114: AddedToken(\"<|reserved_special_token_106|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128115: AddedToken(\"<|reserved_special_token_107|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128116: AddedToken(\"<|reserved_special_token_108|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128117: AddedToken(\"<|reserved_special_token_109|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128118: AddedToken(\"<|reserved_special_token_110|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128119: AddedToken(\"<|reserved_special_token_111|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128120: AddedToken(\"<|reserved_special_token_112|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128121: AddedToken(\"<|reserved_special_token_113|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128122: AddedToken(\"<|reserved_special_token_114|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128123: AddedToken(\"<|reserved_special_token_115|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128124: AddedToken(\"<|reserved_special_token_116|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128125: AddedToken(\"<|reserved_special_token_117|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128126: AddedToken(\"<|reserved_special_token_118|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128127: AddedToken(\"<|reserved_special_token_119|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128128: AddedToken(\"<|reserved_special_token_120|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128129: AddedToken(\"<|reserved_special_token_121|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128130: AddedToken(\"<|reserved_special_token_122|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128131: AddedToken(\"<|reserved_special_token_123|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128132: AddedToken(\"<|reserved_special_token_124|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128133: AddedToken(\"<|reserved_special_token_125|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128134: AddedToken(\"<|reserved_special_token_126|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128135: AddedToken(\"<|reserved_special_token_127|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128136: AddedToken(\"<|reserved_special_token_128|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128137: AddedToken(\"<|reserved_special_token_129|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128138: AddedToken(\"<|reserved_special_token_130|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128139: AddedToken(\"<|reserved_special_token_131|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128140: AddedToken(\"<|reserved_special_token_132|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128141: AddedToken(\"<|reserved_special_token_133|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128142: AddedToken(\"<|reserved_special_token_134|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128143: AddedToken(\"<|reserved_special_token_135|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128144: AddedToken(\"<|reserved_special_token_136|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128145: AddedToken(\"<|reserved_special_token_137|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128146: AddedToken(\"<|reserved_special_token_138|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128147: AddedToken(\"<|reserved_special_token_139|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128148: AddedToken(\"<|reserved_special_token_140|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128149: AddedToken(\"<|reserved_special_token_141|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128150: AddedToken(\"<|reserved_special_token_142|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128151: AddedToken(\"<|reserved_special_token_143|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128152: AddedToken(\"<|reserved_special_token_144|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128153: AddedToken(\"<|reserved_special_token_145|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128154: AddedToken(\"<|reserved_special_token_146|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128155: AddedToken(\"<|reserved_special_token_147|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128156: AddedToken(\"<|reserved_special_token_148|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128157: AddedToken(\"<|reserved_special_token_149|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128158: AddedToken(\"<|reserved_special_token_150|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128159: AddedToken(\"<|reserved_special_token_151|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128160: AddedToken(\"<|reserved_special_token_152|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128161: AddedToken(\"<|reserved_special_token_153|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128162: AddedToken(\"<|reserved_special_token_154|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128163: AddedToken(\"<|reserved_special_token_155|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128164: AddedToken(\"<|reserved_special_token_156|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128165: AddedToken(\"<|reserved_special_token_157|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128166: AddedToken(\"<|reserved_special_token_158|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128167: AddedToken(\"<|reserved_special_token_159|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128168: AddedToken(\"<|reserved_special_token_160|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128169: AddedToken(\"<|reserved_special_token_161|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128170: AddedToken(\"<|reserved_special_token_162|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128171: AddedToken(\"<|reserved_special_token_163|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128172: AddedToken(\"<|reserved_special_token_164|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128173: AddedToken(\"<|reserved_special_token_165|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128174: AddedToken(\"<|reserved_special_token_166|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128175: AddedToken(\"<|reserved_special_token_167|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128176: AddedToken(\"<|reserved_special_token_168|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128177: AddedToken(\"<|reserved_special_token_169|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128178: AddedToken(\"<|reserved_special_token_170|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128179: AddedToken(\"<|reserved_special_token_171|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128180: AddedToken(\"<|reserved_special_token_172|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128181: AddedToken(\"<|reserved_special_token_173|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128182: AddedToken(\"<|reserved_special_token_174|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128183: AddedToken(\"<|reserved_special_token_175|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128184: AddedToken(\"<|reserved_special_token_176|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128185: AddedToken(\"<|reserved_special_token_177|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128186: AddedToken(\"<|reserved_special_token_178|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128187: AddedToken(\"<|reserved_special_token_179|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128188: AddedToken(\"<|reserved_special_token_180|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128189: AddedToken(\"<|reserved_special_token_181|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128190: AddedToken(\"<|reserved_special_token_182|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128191: AddedToken(\"<|reserved_special_token_183|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128192: AddedToken(\"<|reserved_special_token_184|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128193: AddedToken(\"<|reserved_special_token_185|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128194: AddedToken(\"<|reserved_special_token_186|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128195: AddedToken(\"<|reserved_special_token_187|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128196: AddedToken(\"<|reserved_special_token_188|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128197: AddedToken(\"<|reserved_special_token_189|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128198: AddedToken(\"<|reserved_special_token_190|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128199: AddedToken(\"<|reserved_special_token_191|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128200: AddedToken(\"<|reserved_special_token_192|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128201: AddedToken(\"<|reserved_special_token_193|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128202: AddedToken(\"<|reserved_special_token_194|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128203: AddedToken(\"<|reserved_special_token_195|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128204: AddedToken(\"<|reserved_special_token_196|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128205: AddedToken(\"<|reserved_special_token_197|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128206: AddedToken(\"<|reserved_special_token_198|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128207: AddedToken(\"<|reserved_special_token_199|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128208: AddedToken(\"<|reserved_special_token_200|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128209: AddedToken(\"<|reserved_special_token_201|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128210: AddedToken(\"<|reserved_special_token_202|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128211: AddedToken(\"<|reserved_special_token_203|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128212: AddedToken(\"<|reserved_special_token_204|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128213: AddedToken(\"<|reserved_special_token_205|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128214: AddedToken(\"<|reserved_special_token_206|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128215: AddedToken(\"<|reserved_special_token_207|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128216: AddedToken(\"<|reserved_special_token_208|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128217: AddedToken(\"<|reserved_special_token_209|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128218: AddedToken(\"<|reserved_special_token_210|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128219: AddedToken(\"<|reserved_special_token_211|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128220: AddedToken(\"<|reserved_special_token_212|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128221: AddedToken(\"<|reserved_special_token_213|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128222: AddedToken(\"<|reserved_special_token_214|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128223: AddedToken(\"<|reserved_special_token_215|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128224: AddedToken(\"<|reserved_special_token_216|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128225: AddedToken(\"<|reserved_special_token_217|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128226: AddedToken(\"<|reserved_special_token_218|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128227: AddedToken(\"<|reserved_special_token_219|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128228: AddedToken(\"<|reserved_special_token_220|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128229: AddedToken(\"<|reserved_special_token_221|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128230: AddedToken(\"<|reserved_special_token_222|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128231: AddedToken(\"<|reserved_special_token_223|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128232: AddedToken(\"<|reserved_special_token_224|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128233: AddedToken(\"<|reserved_special_token_225|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128234: AddedToken(\"<|reserved_special_token_226|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128235: AddedToken(\"<|reserved_special_token_227|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128236: AddedToken(\"<|reserved_special_token_228|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128237: AddedToken(\"<|reserved_special_token_229|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128238: AddedToken(\"<|reserved_special_token_230|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128239: AddedToken(\"<|reserved_special_token_231|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128240: AddedToken(\"<|reserved_special_token_232|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128241: AddedToken(\"<|reserved_special_token_233|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128242: AddedToken(\"<|reserved_special_token_234|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128243: AddedToken(\"<|reserved_special_token_235|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128244: AddedToken(\"<|reserved_special_token_236|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128245: AddedToken(\"<|reserved_special_token_237|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128246: AddedToken(\"<|reserved_special_token_238|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128247: AddedToken(\"<|reserved_special_token_239|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128248: AddedToken(\"<|reserved_special_token_240|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128249: AddedToken(\"<|reserved_special_token_241|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128250: AddedToken(\"<|reserved_special_token_242|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128251: AddedToken(\"<|reserved_special_token_243|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128252: AddedToken(\"<|reserved_special_token_244|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128253: AddedToken(\"<|reserved_special_token_245|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128254: AddedToken(\"<|reserved_special_token_246|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128255: AddedToken(\"<|reserved_special_token_247|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}\n",
      ")\n",
      "Padding token: <|end_of_text|>\n",
      "Padding token ID: 128001\n",
      "EOS token: <|end_of_text|>\n",
      "EOS token ID: 128001\n",
      "Padding side: right\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Use AutoTokenizer to automatically select the correct tokenizer class\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_id, use_fast=False, trust_remote_code=True, add_eos_token=True)\n",
    "\n",
    "# Add padding token if it doesn't exist\n",
    "if tokenizer.pad_token is None:\n",
    "  tokenizer.add_special_tokens({'pad_token': tokenizer.eos_token})\n",
    "\n",
    "# Set padding side for consistency, often 'left' for generation, 'right' for training/classification\n",
    "# Based on typical Llama usage for generation/training, 'right' is common\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "# Display the tokenizer to confirm it loaded correctly\n",
    "print(tokenizer)\n",
    "print(f\"Padding token: {tokenizer.pad_token}\")\n",
    "print(f\"Padding token ID: {tokenizer.pad_token_id}\")\n",
    "print(f\"EOS token: {tokenizer.eos_token}\")\n",
    "print(f\"EOS token ID: {tokenizer.eos_token_id}\")\n",
    "print(f\"Padding side: {tokenizer.padding_side}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39a5a45b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d71fa671485d4016926f344a92b1c1dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "426e9b1372b54419a073948ed96aeabc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "📊 TOKENIZED DATASET INFO\n",
      "======================================================================\n",
      "\n",
      "📋 TOKENIZED_OUTPUT DATASET INFO:\n",
      "   📊 Total examples: 8\n",
      "   🏗️  Features (19):\n",
      "      • component: Value(dtype='string', id=None)\n",
      "      • card_background: Value(dtype='int64', id=None)\n",
      "      • card_enable: Value(dtype='int64', id=None)\n",
      "      • card_open: Value(dtype='int64', id=None)\n",
      "      • _id: Value(dtype='string', id=None)\n",
      "      • pr_img: Value(dtype='string', id=None)\n",
      "      • name: Value(dtype='string', id=None)\n",
      "      • name_config: {}\n",
      "      • desc: Value(dtype='string', id=None)\n",
      "      • desc_config: {'align': Value(dtype='string', id=None), 'bold': Value(dtype='int64', id=None), 'italic': Value(dtype='int64', id=None), 'lock': Value(dtype='string', id=None)}\n",
      "      • company: Value(dtype='string', id=None)\n",
      "      • contact_shortcut_enable: Value(dtype='int64', id=None)\n",
      "      • enable_pr: Value(dtype='int64', id=None)\n",
      "      • contact_shortcuts: [{'_id': Value(dtype='string', id=None), 'type': Value(dtype='string', id=None), 'type_config': {}, 'value': Value(dtype='string', id=None), 'value_config': {}}]\n",
      "      • show_brand_img: Value(dtype='int64', id=None)\n",
      "      • enable_br: Value(dtype='int64', id=None)\n",
      "      • br_img: Value(dtype='string', id=None)\n",
      "      • input_ids: Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None)\n",
      "      • attention_mask: Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None)\n",
      "\n",
      "   📝 SAMPLE DATA (First Example):\n",
      "      • component: profile\n",
      "      • card_background: 0\n",
      "      • card_enable: 1\n",
      "      • card_open: 1\n",
      "      • _id: uFpMGYHp1750825849079H\n",
      "      • pr_img: https://www.qrcodechimp.com/images/digitalCard/...\n",
      "      • name: Rajan \n",
      "      • name_config: Dict with 0 keys\n",
      "      • desc: Mr\n",
      "      • desc_config: Dict with 4 keys\n",
      "        └─ Keys: ['align', 'bold', 'italic']...\n",
      "      • company: Tez Minds\n",
      "      • contact_shortcut_enable: 1\n",
      "      • enable_pr: 1\n",
      "      • contact_shortcuts: List with 3 items\n",
      "        └─ First item type: <class 'dict'>\n",
      "        └─ Sample keys: ['_id', 'type', 'type_config']...\n",
      "      • show_brand_img: 1\n",
      "      • enable_br: 1\n",
      "      • br_img: https://www.qrcodechimp.com/images/digitalCard/...\n",
      "      • input_ids: List with 3 items\n",
      "        └─ First item type: <class 'int'>\n",
      "      • attention_mask: List with 3 items\n",
      "        └─ First item type: <class 'int'>\n",
      "\n",
      "📋 TOKENIZED_TEMPLATE DATASET INFO:\n",
      "   📊 Total examples: 1\n",
      "   🏗️  Features (4):\n",
      "      • template_id: Value(dtype='string', id=None)\n",
      "      • qr_codes: [{'content': [{'appointments': [{'label': Value(dtype='string', id=None), 'link': Value(dtype='string', id=None)}], 'br_img': Value(dtype='string', id=None), 'card_delete_disabled': Value(dtype='int64', id=None), 'card_desc': Value(dtype='string', id=None), 'card_label': Value(dtype='string', id=None), 'company': Value(dtype='string', id=None), 'component': Value(dtype='string', id=None), 'contact_infos': [{'action_button_label': Value(dtype='string', id=None), 'action_button_link': Value(dtype='string', id=None), 'city': Value(dtype='string', id=None), 'country': Value(dtype='string', id=None), 'email': Value(dtype='string', id=None), 'label': Value(dtype='string', id=None), 'number': Value(dtype='string', id=None), 'state': Value(dtype='string', id=None), 'street': Value(dtype='string', id=None), 'title': Value(dtype='string', id=None), 'type': Value(dtype='string', id=None), 'zip': Value(dtype='string', id=None)}], 'contact_shortcuts': [{'type': Value(dtype='string', id=None), 'value': Value(dtype='string', id=None)}], 'contact_title': Value(dtype='string', id=None), 'desc': Value(dtype='string', id=None), 'desc_config': {'align': Value(dtype='string', id=None), 'bold': Value(dtype='int64', id=None), 'italic': Value(dtype='int64', id=None), 'lock': Value(dtype='string', id=None)}, 'ebusiness_card_enable': Value(dtype='int64', id=None), 'floating_button_label': Value(dtype='string', id=None), 'form_config': [{'button_label': Value(dtype='string', id=None), 'enable_header_img': Value(dtype='int64', id=None), 'form_fields': [{'_id': Value(dtype='string', id=None), 'label': Value(dtype='string', id=None), 'required': Value(dtype='bool', id=None), 'type': Value(dtype='string', id=None)}], 'header': {'desc': Value(dtype='string', id=None), 'header_enable': Value(dtype='int64', id=None), 'title': Value(dtype='string', id=None)}, 'header_img': Value(dtype='string', id=None), 'terms_label': Value(dtype='string', id=None)}], 'form_integration': Sequence(feature=Value(dtype='null', id=None), length=-1, id=None), 'form_name': Value(dtype='string', id=None), 'icon_img': Value(dtype='string', id=None), 'images': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'links': [{'icon_img': Value(dtype='string', id=None), 'subtitle': Value(dtype='string', id=None), 'title': Value(dtype='string', id=None), 'type': Value(dtype='string', id=None), 'url': Value(dtype='string', id=None)}], 'name': Value(dtype='string', id=None), 'pr_img': Value(dtype='string', id=None), 'title': Value(dtype='string', id=None), 'title_config': {'align': Value(dtype='string', id=None), 'bold': Value(dtype='int64', id=None), 'italic': Value(dtype='int64', id=None), 'lock': Value(dtype='string', id=None)}, 'view_config': {'delay_time': Value(dtype='string', id=None), 'dismiss_form': Value(dtype='int64', id=None), 'form_trigger': Value(dtype='string', id=None), 'form_view': Value(dtype='string', id=None), 'view_type': Value(dtype='string', id=None)}, 'view_type': Value(dtype='string', id=None)}], 'qr_name': Value(dtype='string', id=None), 'short_url': Value(dtype='string', id=None)}]\n",
      "      • input_ids: Sequence(feature=Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None), length=-1, id=None)\n",
      "      • attention_mask: Sequence(feature=Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None), length=-1, id=None)\n",
      "\n",
      "   📝 SAMPLE DATA (First Example):\n",
      "      • template_id: b_685bb94064ea9b78d567cade\n",
      "      • qr_codes: List with 1 items\n",
      "        └─ First item type: <class 'dict'>\n",
      "        └─ Sample keys: ['content', 'qr_name', 'short_url']\n",
      "      • input_ids: List with 1 items\n",
      "        └─ First item type: <class 'list'>\n",
      "      • attention_mask: List with 1 items\n",
      "        └─ First item type: <class 'list'>\n",
      "\n",
      "🎉 Tokenization complete for both datasets!\n",
      "You can now proceed with training using 'tokenized_output_dataset' and 'tokenized_template_dataset'.\n"
     ]
    }
   ],
   "source": [
    "# Ensure tokenizer is defined (run cell 8 if not)\n",
    "assert 'tokenizer' in globals(), \"Please run the cell that defines 'tokenizer' (cell 8) before running this cell.\"\n",
    "\n",
    "# Tokenize the datasets using an existing text column.\n",
    "# Replace \"component\" and \"qr_name\" with the actual column(s) you want to tokenize.\n",
    "# Note: template_dataset has 'qr_name' at the top level within the 'qr_codes' list of dictionaries.\n",
    "# We need to access it correctly.\n",
    "\n",
    "# For output_dataset, tokenizing the 'component' column as an example\n",
    "# Batched=True is generally good for larger datasets\n",
    "tokenized_output_dataset = output_dataset.map(\n",
    "    lambda examples: tokenizer(examples[\"component\"], padding=True, truncation=True),\n",
    "    batched=True\n",
    ")\n",
    "\n",
    "# For template_dataset, tokenizing the 'qr_name' within the 'qr_codes' list as an example.\n",
    "# Accessing nested data is simpler with batched=False for small datasets or complex structures\n",
    "tokenized_template_dataset = template_dataset.map(\n",
    "    lambda examples: tokenizer([qr_code['qr_name'] for qr_code in examples['qr_codes']], padding=True, truncation=True),\n",
    "    batched=False # Changed to False to simplify access to nested list of dictionaries\n",
    ")\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"📊 TOKENIZED DATASET INFO\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if tokenized_output_dataset:\n",
    "    display_dataset_info(tokenized_output_dataset, \"tokenized_output\")\n",
    "\n",
    "if tokenized_template_dataset:\n",
    "    display_dataset_info(tokenized_template_dataset, \"tokenized_template\")\n",
    "\n",
    "print(\"\\n🎉 Tokenization complete for both datasets!\")\n",
    "print(\"You can now proceed with training using 'tokenized_output_dataset' and 'tokenized_template_dataset'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "118cda96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|end_of_text|>'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c258ed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb29ef3c3cd34378bf9ea6cc88e06d45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98965f6907114e09ab6093784bba3f88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "📊 FORMATTED DATASET INFO\n",
      "======================================================================\n",
      "Formatted Output Dataset:\n",
      "Dataset({\n",
      "    features: ['component', 'card_background', 'card_enable', 'card_open', '_id', 'pr_img', 'name', 'name_config', 'desc', 'desc_config', 'company', 'contact_shortcut_enable', 'enable_pr', 'contact_shortcuts', 'show_brand_img', 'enable_br', 'br_img', 'input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 8\n",
      "})\n",
      "\n",
      "First example (formatted_output_dataset):\n",
      "  Input IDs: [128000, 5478, 128001]...\n",
      "  Attention Mask: [1, 1, 0]...\n",
      "  Labels: [128000, 5478, 128001]...\n",
      "\n",
      "Formatted Template Dataset:\n",
      "Dataset({\n",
      "    features: ['template_id', 'qr_codes', 'input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 1\n",
      "})\n",
      "\n",
      "First example (formatted_template_dataset):\n",
      "  Input IDs: [[128000]]...\n",
      "  Attention Mask: [[1]]...\n",
      "  Labels: [[128000]]...\n",
      "\n",
      "🎉 Datasets formatted for causal language modeling!\n",
      "You now have 'formatted_output_dataset' and 'formatted_template_dataset' ready for fine-tuning.\n",
      "Remember to combine them or use them as needed for your training setup.\n"
     ]
    }
   ],
   "source": [
    "# Format the tokenized datasets for causal language modeling\n",
    "# This is a general approach; you might need to adjust based on your specific task\n",
    "# (e.g., instruction tuning requires specific chat templates)\n",
    "\n",
    "def format_for_causal_lm(examples):\n",
    "    # Concatenate input_ids and attention_mask\n",
    "    # For simple causal LM, we often train on the entire sequence, so input_ids are the labels\n",
    "    examples[\"labels\"] = examples[\"input_ids\"].copy()\n",
    "    return examples\n",
    "\n",
    "# Apply the formatting function to both tokenized datasets\n",
    "# You might want to combine your datasets before this step for training\n",
    "# For demonstration, applying to both separately\n",
    "formatted_output_dataset = tokenized_output_dataset.map(format_for_causal_lm, batched=True)\n",
    "formatted_template_dataset = tokenized_template_dataset.map(format_for_causal_lm, batched=True)\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"📊 FORMATTED DATASET INFO\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if formatted_output_dataset:\n",
    "    print(\"Formatted Output Dataset:\")\n",
    "    print(formatted_output_dataset)\n",
    "    if len(formatted_output_dataset) > 0:\n",
    "        print(\"\\nFirst example (formatted_output_dataset):\")\n",
    "        # Display input_ids, attention_mask, and labels for the first example\n",
    "        first_example = formatted_output_dataset[0]\n",
    "        print(f\"  Input IDs: {first_example['input_ids'][:50]}...\") # Print first 50 token IDs\n",
    "        print(f\"  Attention Mask: {first_example['attention_mask'][:50]}...\") # Print first 50 attention mask values\n",
    "        print(f\"  Labels: {first_example['labels'][:50]}...\") # Print first 50 label IDs\n",
    "\n",
    "if formatted_template_dataset:\n",
    "    print(\"\\nFormatted Template Dataset:\")\n",
    "    print(formatted_template_dataset)\n",
    "    if len(formatted_template_dataset) > 0:\n",
    "        print(\"\\nFirst example (formatted_template_dataset):\")\n",
    "        # Display input_ids, attention_mask, and labels for the first example\n",
    "        first_example = formatted_template_dataset[0]\n",
    "        print(f\"  Input IDs: {first_example['input_ids'][:50]}...\") # Print first 50 token IDs\n",
    "        print(f\"  Attention Mask: {first_example['attention_mask'][:50]}...\") # Print first 50 attention mask values\n",
    "        print(f\"  Labels: {first_example['labels'][:50]}...\") # Print first 50 label IDs\n",
    "\n",
    "\n",
    "print(\"\\n🎉 Datasets formatted for causal language modeling!\")\n",
    "print(\"You now have 'formatted_output_dataset' and 'formatted_template_dataset' ready for fine-tuning.\")\n",
    "print(\"Remember to combine them or use them as needed for your training setup.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ebb1b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "🔍 DATASET INSPECTION AND CLEANING\n",
      "======================================================================\n",
      "\n",
      "🔍 Inspecting formatted_output_dataset:\n",
      "Dataset type: <class 'datasets.arrow_dataset.Dataset'>\n",
      "📋 Fields in first example: ['component', 'card_background', 'card_enable', 'card_open', '_id', 'pr_img', 'name', 'name_config', 'desc', 'desc_config', 'company', 'contact_shortcut_enable', 'enable_pr', 'contact_shortcuts', 'show_brand_img', 'enable_br', 'br_img', 'input_ids', 'attention_mask', 'labels']\n",
      "\n",
      "  📊 Field 'component':\n",
      "     Type: <class 'str'>\n",
      "     Value preview: 'profile...'\n",
      "     ❌ String field (should be tokenized)\n",
      "\n",
      "  📊 Field 'card_background':\n",
      "     Type: <class 'int'>\n",
      "     ❌ Unexpected type: <class 'int'>\n",
      "\n",
      "  📊 Field 'card_enable':\n",
      "     Type: <class 'int'>\n",
      "     ❌ Unexpected type: <class 'int'>\n",
      "\n",
      "  📊 Field 'card_open':\n",
      "     Type: <class 'int'>\n",
      "     ❌ Unexpected type: <class 'int'>\n",
      "\n",
      "  📊 Field '_id':\n",
      "     Type: <class 'str'>\n",
      "     Value preview: 'uFpMGYHp1750825849079H...'\n",
      "     ❌ String field (should be tokenized)\n",
      "\n",
      "  📊 Field 'pr_img':\n",
      "     Type: <class 'str'>\n",
      "     Value preview: 'https://www.qrcodechimp.com/images/digitalCard/dbcv2/profile_1.webp?v=1750825849004...'\n",
      "     ❌ String field (should be tokenized)\n",
      "\n",
      "  📊 Field 'name':\n",
      "     Type: <class 'str'>\n",
      "     Value preview: 'Rajan ...'\n",
      "     ❌ String field (should be tokenized)\n",
      "\n",
      "  📊 Field 'name_config':\n",
      "     Type: <class 'dict'>\n",
      "     ❌ Unexpected type: <class 'dict'>\n",
      "\n",
      "  📊 Field 'desc':\n",
      "     Type: <class 'str'>\n",
      "     Value preview: 'Mr...'\n",
      "     ❌ String field (should be tokenized)\n",
      "\n",
      "  📊 Field 'desc_config':\n",
      "     Type: <class 'dict'>\n",
      "     ❌ Unexpected type: <class 'dict'>\n",
      "\n",
      "  📊 Field 'company':\n",
      "     Type: <class 'str'>\n",
      "     Value preview: 'Tez Minds...'\n",
      "     ❌ String field (should be tokenized)\n",
      "\n",
      "  📊 Field 'contact_shortcut_enable':\n",
      "     Type: <class 'int'>\n",
      "     ❌ Unexpected type: <class 'int'>\n",
      "\n",
      "  📊 Field 'enable_pr':\n",
      "     Type: <class 'int'>\n",
      "     ❌ Unexpected type: <class 'int'>\n",
      "\n",
      "  📊 Field 'contact_shortcuts':\n",
      "     Type: <class 'list'>\n",
      "     Length: 3\n",
      "     First element type: <class 'dict'>\n",
      "     First few elements: [{'_id': 'woMsSJ9x17508258490051', 'type': 'mobile', 'type_config': {}, 'value': '9709590075', 'value_config': {}}, {'_id': '3xyoEBz117508258490052', 'type': 'email', 'type_config': {}, 'value': 'rajang797@gmail.com', 'value_config': {}}, {'_id': '92zAMWLI17508258490053', 'type': 'sms', 'type_config': {}, 'value': '9709590075', 'value_config': {}}]\n",
      "     ❌ Problematic (not all integers)\n",
      "\n",
      "  📊 Field 'show_brand_img':\n",
      "     Type: <class 'int'>\n",
      "     ❌ Unexpected type: <class 'int'>\n",
      "\n",
      "  📊 Field 'enable_br':\n",
      "     Type: <class 'int'>\n",
      "     ❌ Unexpected type: <class 'int'>\n",
      "\n",
      "  📊 Field 'br_img':\n",
      "     Type: <class 'str'>\n",
      "     Value preview: 'https://www.qrcodechimp.com/images/digitalCard/dbcv2/barand_logo_9.webp?v=1750825849004...'\n",
      "     ❌ String field (should be tokenized)\n",
      "\n",
      "  📊 Field 'input_ids':\n",
      "     Type: <class 'list'>\n",
      "     Length: 3\n",
      "     First element type: <class 'int'>\n",
      "     First few elements: [128000, 5478, 128001]\n",
      "     ✅ Looks good (list of integers)\n",
      "\n",
      "  📊 Field 'attention_mask':\n",
      "     Type: <class 'list'>\n",
      "     Length: 3\n",
      "     First element type: <class 'int'>\n",
      "     First few elements: [1, 1, 0]\n",
      "     ✅ Looks good (list of integers)\n",
      "\n",
      "  📊 Field 'labels':\n",
      "     Type: <class 'list'>\n",
      "     Length: 3\n",
      "     First element type: <class 'int'>\n",
      "     First few elements: [128000, 5478, 128001]\n",
      "     ✅ Looks good (list of integers)\n",
      "\n",
      "✅ Good fields: ['input_ids', 'attention_mask', 'labels']\n",
      "❌ Problematic fields: ['component', 'card_background', 'card_enable', 'card_open', '_id', 'pr_img', 'name', 'name_config', 'desc', 'desc_config', 'company', 'contact_shortcut_enable', 'enable_pr', 'contact_shortcuts', 'show_brand_img', 'enable_br', 'br_img']\n",
      "\n",
      "🎯 Method 1: Using existing good fields...\n",
      "\n",
      "🧹 Cleaning dataset...\n",
      "✅ Created clean dataset with 8 examples\n",
      "\n",
      "✅ Using clean dataset with 8 examples\n",
      "\n",
      "🧪 Testing clean dataset structure...\n",
      "Clean dataset first example:\n",
      "  input_ids: type=<class 'list'>, length=3, sample=[128000, 5478, 128001]...\n",
      "  attention_mask: type=<class 'list'>, length=3, sample=[1, 1, 0]...\n",
      "  labels: type=<class 'list'>, length=3, sample=[128000, 5478, 128001]...\n",
      "\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 0 || all params: 1,241,450,496 || trainable%: 0.0000\n",
      "\n",
      "🧪 Testing data collator with clean dataset...\n",
      "✅ Data collator test successful!\n",
      "Batch keys: ['input_ids', 'attention_mask', 'labels']\n",
      "  input_ids: shape=torch.Size([2, 3]), dtype=torch.int64\n",
      "  attention_mask: shape=torch.Size([2, 3]), dtype=torch.int64\n",
      "  labels: shape=torch.Size([2, 3]), dtype=torch.int64\n",
      "\n",
      "======================================================================\n",
      "🚀 STARTING TRAINING WITH CLEAN DATASET\n",
      "======================================================================\n",
      "🏃 Beginning training loop...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:19, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6.629600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>7.508900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>7.487600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>6.658900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6.853900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>7.394900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>6.658900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>7.487600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>7.595500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>6.510400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎉 Training completed successfully!\n",
      "\n",
      "======================================================================\n",
      "✅ TRAINING COMPLETE\n",
      "======================================================================\n",
      "💾 Saving model...\n",
      "✅ Model saved successfully!\n",
      "\n",
      "📊 Final dataset info: 8 examples successfully processed\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "from datasets import Dataset\n",
    "\n",
    "def clean_and_inspect_dataset(dataset, dataset_name=\"dataset\"):\n",
    "    \"\"\"\n",
    "    Clean the dataset and inspect its structure to identify problematic fields\n",
    "    \"\"\"\n",
    "    print(f\"\\n🔍 Inspecting {dataset_name}:\")\n",
    "    print(f\"Dataset type: {type(dataset)}\")\n",
    "    \n",
    "    if len(dataset) == 0:\n",
    "        print(\"❌ Dataset is empty!\")\n",
    "        return None\n",
    "    \n",
    "    # Look at the first example in detail\n",
    "    first_example = dataset[0]\n",
    "    print(f\"📋 Fields in first example: {list(first_example.keys())}\")\n",
    "    \n",
    "    # Analyze each field\n",
    "    problematic_fields = []\n",
    "    good_fields = {}\n",
    "    \n",
    "    for field_name, value in first_example.items():\n",
    "        print(f\"\\n  📊 Field '{field_name}':\")\n",
    "        print(f\"     Type: {type(value)}\")\n",
    "        \n",
    "        if isinstance(value, list):\n",
    "            if len(value) > 0:\n",
    "                print(f\"     Length: {len(value)}\")\n",
    "                print(f\"     First element type: {type(value[0])}\")\n",
    "                print(f\"     First few elements: {value[:5]}\")\n",
    "                \n",
    "                # Check if it's a list of integers (good for input_ids, labels, attention_mask)\n",
    "                if all(isinstance(x, int) for x in value[:10]):  # Check first 10 elements\n",
    "                    good_fields[field_name] = value\n",
    "                    print(f\"     ✅ Looks good (list of integers)\")\n",
    "                else:\n",
    "                    problematic_fields.append(field_name)\n",
    "                    print(f\"     ❌ Problematic (not all integers)\")\n",
    "            else:\n",
    "                problematic_fields.append(field_name)\n",
    "                print(f\"     ❌ Empty list\")\n",
    "        elif isinstance(value, str):\n",
    "            print(f\"     Value preview: '{value[:100]}...'\")\n",
    "            problematic_fields.append(field_name)\n",
    "            print(f\"     ❌ String field (should be tokenized)\")\n",
    "        else:\n",
    "            problematic_fields.append(field_name)\n",
    "            print(f\"     ❌ Unexpected type: {type(value)}\")\n",
    "    \n",
    "    print(f\"\\n✅ Good fields: {list(good_fields.keys())}\")\n",
    "    print(f\"❌ Problematic fields: {problematic_fields}\")\n",
    "    \n",
    "    return good_fields, problematic_fields\n",
    "\n",
    "def create_clean_dataset(original_dataset, required_fields=['input_ids', 'attention_mask', 'labels']):\n",
    "    \"\"\"\n",
    "    Create a clean dataset with only the required fields\n",
    "    \"\"\"\n",
    "    print(f\"\\n🧹 Cleaning dataset...\")\n",
    "    \n",
    "    clean_examples = []\n",
    "    \n",
    "    for i, example in enumerate(original_dataset):\n",
    "        clean_example = {}\n",
    "        valid_example = True\n",
    "        \n",
    "        # Extract only the required fields\n",
    "        for field in required_fields:\n",
    "            if field in example:\n",
    "                value = example[field]\n",
    "                \n",
    "                # Ensure it's a list of integers\n",
    "                if isinstance(value, list) and len(value) > 0:\n",
    "                    if all(isinstance(x, int) for x in value):\n",
    "                        clean_example[field] = value\n",
    "                    else:\n",
    "                        print(f\"❌ Example {i}: {field} contains non-integers\")\n",
    "                        valid_example = False\n",
    "                        break\n",
    "                else:\n",
    "                    print(f\"❌ Example {i}: {field} is not a valid list\")\n",
    "                    valid_example = False\n",
    "                    break\n",
    "            else:\n",
    "                print(f\"❌ Example {i}: Missing field {field}\")\n",
    "                valid_example = False\n",
    "                break\n",
    "        \n",
    "        if valid_example:\n",
    "            clean_examples.append(clean_example)\n",
    "        else:\n",
    "            print(f\"⚠️ Skipping example {i} due to invalid data\")\n",
    "    \n",
    "    if clean_examples:\n",
    "        clean_dataset = Dataset.from_list(clean_examples)\n",
    "        print(f\"✅ Created clean dataset with {len(clean_dataset)} examples\")\n",
    "        return clean_dataset\n",
    "    else:\n",
    "        print(\"❌ No valid examples found!\")\n",
    "        return None\n",
    "\n",
    "def fix_dataset_structure(dataset):\n",
    "    \"\"\"\n",
    "    Alternative approach: try to fix the dataset structure automatically\n",
    "    \"\"\"\n",
    "    print(f\"\\n🔧 Attempting to fix dataset structure...\")\n",
    "    \n",
    "    if len(dataset) == 0:\n",
    "        return None\n",
    "    \n",
    "    # Look for the pattern in your data\n",
    "    first_example = dataset[0]\n",
    "    \n",
    "    # Common problematic patterns and fixes\n",
    "    fixed_examples = []\n",
    "    \n",
    "    for i, example in enumerate(dataset):\n",
    "        try:\n",
    "            fixed_example = {}\n",
    "            \n",
    "            # Handle different field names and structures\n",
    "            for field_name, value in example.items():\n",
    "                if field_name in ['input_ids', 'attention_mask', 'labels']:\n",
    "                    if isinstance(value, list):\n",
    "                        # Ensure all elements are integers\n",
    "                        if all(isinstance(x, int) for x in value):\n",
    "                            fixed_example[field_name] = value\n",
    "                        else:\n",
    "                            # Try to convert to integers if possible\n",
    "                            try:\n",
    "                                fixed_example[field_name] = [int(x) for x in value]\n",
    "                            except (ValueError, TypeError):\n",
    "                                print(f\"❌ Cannot convert {field_name} to integers in example {i}\")\n",
    "                                break\n",
    "                    else:\n",
    "                        print(f\"❌ {field_name} is not a list in example {i}\")\n",
    "                        break\n",
    "                # Skip other fields (like 'component' which is causing issues)\n",
    "            \n",
    "            # Only add if we have all required fields\n",
    "            if all(field in fixed_example for field in ['input_ids', 'attention_mask', 'labels']):\n",
    "                fixed_examples.append(fixed_example)\n",
    "            else:\n",
    "                print(f\"⚠️ Example {i} missing required fields\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing example {i}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    if fixed_examples:\n",
    "        return Dataset.from_list(fixed_examples)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# =============================================================================\n",
    "# DATASET CLEANING AND INSPECTION\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"🔍 DATASET INSPECTION AND CLEANING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# First, let's inspect your current dataset\n",
    "good_fields, problematic_fields = clean_and_inspect_dataset(formatted_output_dataset, \"formatted_output_dataset\")\n",
    "\n",
    "# Try to create a clean dataset\n",
    "clean_dataset = None\n",
    "\n",
    "# Method 1: Extract only good fields\n",
    "if good_fields and all(field in good_fields for field in ['input_ids', 'attention_mask', 'labels']):\n",
    "    print(\"\\n🎯 Method 1: Using existing good fields...\")\n",
    "    clean_dataset = create_clean_dataset(formatted_output_dataset)\n",
    "\n",
    "# Method 2: Fix dataset structure\n",
    "if clean_dataset is None:\n",
    "    print(\"\\n🎯 Method 2: Attempting to fix dataset structure...\")\n",
    "    clean_dataset = fix_dataset_structure(formatted_output_dataset)\n",
    "\n",
    "# Method 3: Manual reconstruction if needed\n",
    "if clean_dataset is None:\n",
    "    print(\"\\n🎯 Method 3: Manual dataset reconstruction...\")\n",
    "    print(\"Your dataset might need manual reconstruction. Let's see what we can extract:\")\n",
    "    \n",
    "    # Show detailed structure of first few examples\n",
    "    for i in range(min(3, len(formatted_output_dataset))):\n",
    "        print(f\"\\nExample {i}:\")\n",
    "        example = formatted_output_dataset[i]\n",
    "        for key, value in example.items():\n",
    "            if isinstance(value, list):\n",
    "                print(f\"  {key}: list[{len(value)}] - {value[:10]}...\")\n",
    "            elif isinstance(value, str):\n",
    "                print(f\"  {key}: str - '{value[:50]}...'\")\n",
    "            else:\n",
    "                print(f\"  {key}: {type(value)} - {value}\")\n",
    "\n",
    "if clean_dataset is None:\n",
    "    print(\"\\n❌ Could not create a clean dataset. Please check your data structure.\")\n",
    "    print(\"The dataset should have 'input_ids', 'attention_mask', and 'labels' fields,\")\n",
    "    print(\"each containing lists of integers.\")\n",
    "    exit()\n",
    "\n",
    "# =============================================================================\n",
    "# TRAINING SETUP WITH CLEAN DATASET\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\n✅ Using clean dataset with {len(clean_dataset)} examples\")\n",
    "\n",
    "# Test the clean dataset structure\n",
    "print(\"\\n🧪 Testing clean dataset structure...\")\n",
    "test_example = clean_dataset[0]\n",
    "print(\"Clean dataset first example:\")\n",
    "for key, value in test_example.items():\n",
    "    print(f\"  {key}: type={type(value)}, length={len(value)}, sample={value[:5]}...\")\n",
    "\n",
    "# Setup model for training\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"\\nUsing device: {device}\")\n",
    "\n",
    "# Apply LoRA (unload existing adapters first if they exist)\n",
    "model = model.cpu()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "if hasattr(model, 'peft_config'):\n",
    "    print(\"⚠️ Unloading existing PEFT adapters...\")\n",
    "    model = model.unload()\n",
    "\n",
    "config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    bias=\"none\",\n",
    "    lora_dropout=0.05,\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, config)\n",
    "model = prepare_model_for_kbit_training(model, use_gradient_checkpointing=True)\n",
    "model = model.to(device)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "# Simple, robust data collator\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False,\n",
    "    pad_to_multiple_of=None,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "# Test the data collator with clean dataset\n",
    "print(\"\\n🧪 Testing data collator with clean dataset...\")\n",
    "try:\n",
    "    test_samples = [clean_dataset[i] for i in range(min(2, len(clean_dataset)))]\n",
    "    test_batch = data_collator(test_samples)\n",
    "    \n",
    "    print(\"✅ Data collator test successful!\")\n",
    "    print(f\"Batch keys: {list(test_batch.keys())}\")\n",
    "    for key, value in test_batch.items():\n",
    "        if torch.is_tensor(value):\n",
    "            print(f\"  {key}: shape={value.shape}, dtype={value.dtype}\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"❌ Data collator test still failing: {e}\")\n",
    "    print(\"\\nLet's try a custom data collator...\")\n",
    "    \n",
    "    # Custom data collator as last resort\n",
    "    def custom_data_collator(features):\n",
    "        # Manual batching\n",
    "        batch = {}\n",
    "        keys = features[0].keys()\n",
    "        \n",
    "        for key in keys:\n",
    "            values = [f[key] for f in features]\n",
    "            \n",
    "            # Find max length for padding\n",
    "            max_len = max(len(v) for v in values)\n",
    "            \n",
    "            # Pad sequences\n",
    "            padded_values = []\n",
    "            for v in values:\n",
    "                if len(v) < max_len:\n",
    "                    if key == 'labels':\n",
    "                        # Pad labels with -100 (ignore index)\n",
    "                        padded = v + [-100] * (max_len - len(v))\n",
    "                    else:\n",
    "                        # Pad other fields with 0\n",
    "                        padded = v + [0] * (max_len - len(v))\n",
    "                else:\n",
    "                    padded = v\n",
    "                padded_values.append(padded)\n",
    "            \n",
    "            batch[key] = torch.tensor(padded_values, dtype=torch.long)\n",
    "        \n",
    "        return batch\n",
    "    \n",
    "    # Test custom collator\n",
    "    try:\n",
    "        test_batch = custom_data_collator(test_samples)\n",
    "        print(\"✅ Custom data collator works!\")\n",
    "        data_collator = custom_data_collator\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Even custom data collator failed: {e}\")\n",
    "        exit()\n",
    "\n",
    "# Training arguments\n",
    "training_args = transformers.TrainingArguments(\n",
    "    output_dir=\"./finetunedModel\",\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=2,\n",
    "    learning_rate=1e-4,\n",
    "    max_steps=10,  # Small number for testing\n",
    "    bf16=torch.cuda.is_available() and torch.cuda.get_device_properties(0).major >= 8,\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "    logging_dir=\"./log\",\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=5,\n",
    "    logging_steps=1,\n",
    "    report_to=\"none\",\n",
    "    dataloader_pin_memory=False,\n",
    "    dataloader_num_workers=0,\n",
    "    remove_unused_columns=False,\n",
    "    gradient_checkpointing=True,\n",
    "    logging_first_step=True,\n",
    "    eval_strategy=\"no\",\n",
    ")\n",
    "\n",
    "model.config.use_cache = False\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    train_dataset=clean_dataset,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    processing_class=tokenizer,  # Use processing_class instead of tokenizer (new API)\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"🚀 STARTING TRAINING WITH CLEAN DATASET\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "try:\n",
    "    trainer.model.zero_grad()\n",
    "    print(\"🏃 Beginning training loop...\")\n",
    "    trainer.train()\n",
    "    print(\"\\n🎉 Training completed successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ Training error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"✅ TRAINING COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Save model if training succeeded\n",
    "if hasattr(trainer, 'state') and trainer.state.global_step > 0:\n",
    "    print(\"💾 Saving model...\")\n",
    "    trainer.save_model(\"./finetunedModel\")\n",
    "    tokenizer.save_pretrained(\"./finetunedModel\")\n",
    "    print(\"✅ Model saved successfully!\")\n",
    "else:\n",
    "    print(\"⚠️ No training progress, model not saved.\")\n",
    "\n",
    "print(f\"\\n📊 Final dataset info: {len(clean_dataset)} examples successfully processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7fbc0ada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(128256, 2048)\n",
       "        (layers): ModuleList(\n",
       "          (0-15): 16 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=2048, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=512, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=512, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=512, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=512, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=2048, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=8192, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=8192, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=8192, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=8192, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=8192, out_features=2048, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=8192, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=2048, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=2048, out_features=128256, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from peft import PeftModel\n",
    "import torch\n",
    "\n",
    "base_model_id = \"meta-llama/Llama-3.2-1B\"  # replace with your correct model\n",
    "\n",
    "nf4_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_id, use_fast=False)\n",
    "\n",
    "# Fix pad token\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': tokenizer.eos_token})\n",
    "\n",
    "# Load model\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_id,\n",
    "    quantization_config=nf4_config,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# Load PEFT adapter\n",
    "peft_model_path = \"./finetunedModel/checkpoint-10\"\n",
    "model = PeftModel.from_pretrained(base_model, peft_model_path)\n",
    "\n",
    "# Set to eval mode\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f81a9162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Fine-tuned model loaded and set to evaluation mode.\n",
      "Adapter loaded from: ./finetunedModel/checkpoint-10\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from peft import PeftModel\n",
    "import torch\n",
    "\n",
    "base_model_id = \"meta-llama/Llama-3.2-1B\"\n",
    "\n",
    "nf4Config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "# ✅ Use auto device placement (no manual map)\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_id,\n",
    "    quantization_config=nf4Config,\n",
    "    device_map={\"\": \"cpu\"},  # Force all layers to CPU\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "\n",
    "# Load PEFT adapter\n",
    "peft_model_id = \"./finetunedModel/checkpoint-10\"\n",
    "model = PeftModel.from_pretrained(base_model, peft_model_id)\n",
    "\n",
    "# Prepare tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_id, use_fast=False, trust_remote_code=True)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': tokenizer.eos_token})\n",
    "\n",
    "model.eval()\n",
    "\n",
    "print(\"\\n✅ Fine-tuned model loaded and set to evaluation mode.\")\n",
    "print(f\"Adapter loaded from: {peft_model_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "57c9694d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "/home/rajan/Documents/leanPython/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:2479: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cuda, whereas the model is on cpu. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cpu') before running `.generate()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper_CUDA__index_select)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m model.eval()\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m   \u001b[38;5;28mprint\u001b[39m(tokenizer.decode(\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpromptTokenized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1024\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m], skip_special_tokens=\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[32m     11\u001b[39m   torch.cuda.empty_cache()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/leanPython/.venv/lib/python3.12/site-packages/peft/peft_model.py:1875\u001b[39m, in \u001b[36mPeftModelForCausalLM.generate\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1873\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._enable_peft_forward_hooks(*args, **kwargs):\n\u001b[32m   1874\u001b[39m         kwargs = {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.special_peft_forward_args}\n\u001b[32m-> \u001b[39m\u001b[32m1875\u001b[39m         outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbase_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1876\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1877\u001b[39m     outputs = \u001b[38;5;28mself\u001b[39m.base_model.generate(**kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/leanPython/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/leanPython/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:2597\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[39m\n\u001b[32m   2589\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   2590\u001b[39m         input_ids=input_ids,\n\u001b[32m   2591\u001b[39m         expand_size=generation_config.num_return_sequences,\n\u001b[32m   2592\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2593\u001b[39m         **model_kwargs,\n\u001b[32m   2594\u001b[39m     )\n\u001b[32m   2596\u001b[39m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2597\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2598\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2599\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2600\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2601\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2602\u001b[39m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m=\u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2603\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2604\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2605\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2607\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode.BEAM_SAMPLE, GenerationMode.BEAM_SEARCH):\n\u001b[32m   2608\u001b[39m     \u001b[38;5;66;03m# 11. interleave input_ids with `num_beams` additional sequences per batch\u001b[39;00m\n\u001b[32m   2609\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   2610\u001b[39m         input_ids=input_ids,\n\u001b[32m   2611\u001b[39m         expand_size=generation_config.num_beams,\n\u001b[32m   2612\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2613\u001b[39m         **model_kwargs,\n\u001b[32m   2614\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/leanPython/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:3557\u001b[39m, in \u001b[36mGenerationMixin._sample\u001b[39m\u001b[34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[39m\n\u001b[32m   3554\u001b[39m model_inputs.update({\u001b[33m\"\u001b[39m\u001b[33moutput_hidden_states\u001b[39m\u001b[33m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[32m   3556\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_prefill:\n\u001b[32m-> \u001b[39m\u001b[32m3557\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   3558\u001b[39m     is_prefill = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   3559\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/leanPython/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/leanPython/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/leanPython/.venv/lib/python3.12/site-packages/accelerate/hooks.py:175\u001b[39m, in \u001b[36madd_hook_to_module.<locals>.new_forward\u001b[39m\u001b[34m(module, *args, **kwargs)\u001b[39m\n\u001b[32m    173\u001b[39m         output = module._old_forward(*args, **kwargs)\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m     output = \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m module._hf_hook.post_forward(module, output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/leanPython/.venv/lib/python3.12/site-packages/transformers/utils/generic.py:969\u001b[39m, in \u001b[36mcan_return_tuple.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    966\u001b[39m     set_attribute_for_modules(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_is_top_level_module\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    968\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m969\u001b[39m     output = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    970\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_requested_to_return_tuple \u001b[38;5;129;01mor\u001b[39;00m (is_configured_to_return_tuple \u001b[38;5;129;01mand\u001b[39;00m is_top_level_module):\n\u001b[32m    971\u001b[39m         output = output.to_tuple()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/leanPython/.venv/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py:688\u001b[39m, in \u001b[36mLlamaForCausalLM.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, cache_position, logits_to_keep, **kwargs)\u001b[39m\n\u001b[32m    683\u001b[39m output_hidden_states = (\n\u001b[32m    684\u001b[39m     output_hidden_states \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.output_hidden_states\n\u001b[32m    685\u001b[39m )\n\u001b[32m    687\u001b[39m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m688\u001b[39m outputs: BaseModelOutputWithPast = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    689\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    690\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    691\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    692\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    693\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    694\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    695\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    696\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    697\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    698\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    699\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    701\u001b[39m hidden_states = outputs.last_hidden_state\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/leanPython/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/leanPython/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/leanPython/.venv/lib/python3.12/site-packages/transformers/utils/generic.py:969\u001b[39m, in \u001b[36mcan_return_tuple.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    966\u001b[39m     set_attribute_for_modules(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_is_top_level_module\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    968\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m969\u001b[39m     output = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    970\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_requested_to_return_tuple \u001b[38;5;129;01mor\u001b[39;00m (is_configured_to_return_tuple \u001b[38;5;129;01mand\u001b[39;00m is_top_level_module):\n\u001b[32m    971\u001b[39m         output = output.to_tuple()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/leanPython/.venv/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py:422\u001b[39m, in \u001b[36mLlamaModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, cache_position, **flash_attn_kwargs)\u001b[39m\n\u001b[32m    419\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mThe `past_key_values` should be either a `Cache` object or `None`.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    421\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m422\u001b[39m     inputs_embeds = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membed_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    424\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mand\u001b[39;00m past_key_values \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    425\u001b[39m     past_key_values = DynamicCache()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/leanPython/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/leanPython/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/leanPython/.venv/lib/python3.12/site-packages/torch/nn/modules/sparse.py:190\u001b[39m, in \u001b[36mEmbedding.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/leanPython/.venv/lib/python3.12/site-packages/torch/nn/functional.py:2551\u001b[39m, in \u001b[36membedding\u001b[39m\u001b[34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[39m\n\u001b[32m   2545\u001b[39m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[32m   2546\u001b[39m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[32m   2547\u001b[39m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[32m   2548\u001b[39m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[32m   2549\u001b[39m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[32m   2550\u001b[39m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[32m-> \u001b[39m\u001b[32m2551\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper_CUDA__index_select)"
     ]
    }
   ],
   "source": [
    "user_question = \"do you know qrcode componant and desc and links\"\n",
    "\n",
    "eval_prompt = f\"Question: {user_question} Just answer this question accurately and concisely.\\n\"\n",
    "\n",
    "promptTokenized = tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "  print(tokenizer.decode(model.generate(**promptTokenized, max_new_tokens=1024)[0], skip_special_tokens=True))\n",
    "  torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e42d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in ./.venv/lib/python3.12/site-packages (0.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'PreTrainedTokenizerFast'. \n",
      "The class this function is called from is 'LlamaTokenizer'.\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "not a string",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m get_ipython().system(\u001b[33m'\u001b[39m\u001b[33mpip install sentencepiece\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m tokenizer = \u001b[43mLlamaTokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_model_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_fast\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_eos_token\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m      4\u001b[39m \n\u001b[32m      5\u001b[39m \u001b[43m                              \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m modelFinetuned = PeftModel.from_pretrained(base_model, \u001b[33m\"\u001b[39m\u001b[33mfinetunedModel/checkpoint-10\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/leanPython/.venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:2025\u001b[39m, in \u001b[36mPreTrainedTokenizerBase.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[39m\n\u001b[32m   2022\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2023\u001b[39m         logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mloading file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m from cache at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresolved_vocab_files[file_id]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2025\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_from_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2026\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresolved_vocab_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2027\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2028\u001b[39m \u001b[43m    \u001b[49m\u001b[43minit_configuration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2029\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43minit_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2030\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2031\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2032\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2033\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2034\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_is_local\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_local\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2035\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2036\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2037\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/leanPython/.venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:2278\u001b[39m, in \u001b[36mPreTrainedTokenizerBase._from_pretrained\u001b[39m\u001b[34m(cls, resolved_vocab_files, pretrained_model_name_or_path, init_configuration, token, cache_dir, local_files_only, _commit_hash, _is_local, trust_remote_code, *init_inputs, **kwargs)\u001b[39m\n\u001b[32m   2276\u001b[39m \u001b[38;5;66;03m# Instantiate the tokenizer.\u001b[39;00m\n\u001b[32m   2277\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2278\u001b[39m     tokenizer = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43minit_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2279\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m import_protobuf_decode_error():\n\u001b[32m   2280\u001b[39m     logger.info(\n\u001b[32m   2281\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mUnable to load tokenizer model from SPM, loading from TikToken will be attempted instead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2282\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m(Google protobuf error: Tried to load SPM model with non-SPM vocab file).\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2283\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/leanPython/.venv/lib/python3.12/site-packages/transformers/models/llama/tokenization_llama.py:171\u001b[39m, in \u001b[36mLlamaTokenizer.__init__\u001b[39m\u001b[34m(self, vocab_file, unk_token, bos_token, eos_token, pad_token, sp_model_kwargs, add_bos_token, add_eos_token, clean_up_tokenization_spaces, use_default_system_prompt, spaces_between_special_tokens, legacy, add_prefix_space, **kwargs)\u001b[39m\n\u001b[32m    169\u001b[39m \u001b[38;5;28mself\u001b[39m.add_eos_token = add_eos_token\n\u001b[32m    170\u001b[39m \u001b[38;5;28mself\u001b[39m.use_default_system_prompt = use_default_system_prompt\n\u001b[32m--> \u001b[39m\u001b[32m171\u001b[39m \u001b[38;5;28mself\u001b[39m.sp_model = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_spm_processor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrom_slow\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[38;5;28mself\u001b[39m.add_prefix_space = add_prefix_space\n\u001b[32m    174\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\n\u001b[32m    175\u001b[39m     bos_token=bos_token,\n\u001b[32m    176\u001b[39m     eos_token=eos_token,\n\u001b[32m   (...)\u001b[39m\u001b[32m    187\u001b[39m     **kwargs,\n\u001b[32m    188\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/leanPython/.venv/lib/python3.12/site-packages/transformers/models/llama/tokenization_llama.py:198\u001b[39m, in \u001b[36mLlamaTokenizer.get_spm_processor\u001b[39m\u001b[34m(self, from_slow)\u001b[39m\n\u001b[32m    196\u001b[39m tokenizer = spm.SentencePieceProcessor(**\u001b[38;5;28mself\u001b[39m.sp_model_kwargs)\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.legacy \u001b[38;5;129;01mor\u001b[39;00m from_slow:  \u001b[38;5;66;03m# no dependency on protobuf\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m     \u001b[43mtokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLoad\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvocab_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    199\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer\n\u001b[32m    201\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m.vocab_file, \u001b[33m\"\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/leanPython/.venv/lib/python3.12/site-packages/sentencepiece/__init__.py:961\u001b[39m, in \u001b[36mSentencePieceProcessor.Load\u001b[39m\u001b[34m(self, model_file, model_proto)\u001b[39m\n\u001b[32m    959\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model_proto:\n\u001b[32m    960\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.LoadFromSerializedProto(model_proto)\n\u001b[32m--> \u001b[39m\u001b[32m961\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mLoadFromFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/leanPython/.venv/lib/python3.12/site-packages/sentencepiece/__init__.py:316\u001b[39m, in \u001b[36mSentencePieceProcessor.LoadFromFile\u001b[39m\u001b[34m(self, arg)\u001b[39m\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mLoadFromFile\u001b[39m(\u001b[38;5;28mself\u001b[39m, arg):\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_sentencepiece\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSentencePieceProcessor_LoadFromFile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: not a string"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenizer = LlamaTokenizer.from_pretrained(base_model_id, use_fast=False, trust_remote_code=True, add_eos_token=True\n",
    "\n",
    "                              )\n",
    "\n",
    "modelFinetuned = PeftModel.from_pretrained(base_model, \"finetunedModel/checkpoint-10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2c7cff83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating text with prompt: '\n",
      "You are a JSON generation system that formats user business card data into structured JSON.\n",
      "\n",
      "You will receive:\n",
      "1. User information (name, phone, email, company, etc.)\n",
      "2. A JSON template with placeholders or default data.\n",
      "\n",
      "Your task is:\n",
      "- Parse the user info and merge it into the template\n",
      "- Replace placeholders in JSON with actual user values\n",
      "- Ensure the JSON format remains valid and fully populated\n",
      "- Do not skip any components (e.g., profile, contact, web_links, etc.)\n",
      "- Return ONLY a JSON array as final output (no explanation or extra notes)\n",
      "\n",
      "User Info:\n",
      "Name: Rajan\n",
      "Designation: Mr\n",
      "Company: Tez Minds\n",
      "Phone: 9709590075\n",
      "Email: rajang797@gmail.com\n",
      "Website: https://www.mycoolbrand.com\n",
      "Socials: Facebook, Instagram, Twitter\n",
      "Description: Description\n",
      "Address: Street, City, State, Zipcode, Country\n",
      "Calendly: Link to book meetings\n",
      "\n",
      "JSON Template:\n",
      "(paste your full template JSON array here)\n",
      "\n",
      "Now output the updated JSON:\n",
      "[\n",
      "    {\n",
      "        \"component\": \"profile\",\n",
      "        \"card_background\": 0,\n",
      "        \"card_enable\": 1,\n",
      "        \"card_open\": 1,\n",
      "        \"_id\": \"uFpMGYHp1750825849079H\",\n",
      "        \"pr_img\": \"https://www.qrcodechimp.com/images/digitalCard/dbcv2/profile_1.webp?v=1750825849004\",\n",
      "        \"name\": \"Rajan \",\n",
      "        \"name_config\": {},\n",
      "        \"desc\": \"Mr\",\n",
      "        \"desc_config\": {},\n",
      "        \"company\": \"Tez Minds\",\n",
      "        \"contact_shortcut_enable\": 1,\n",
      "        \"enable_pr\": 1,\n",
      "        \"contact_shortcuts\": [\n",
      "            {\n",
      "                \"_id\": \"woMsSJ9x17508258490051\",\n",
      "                \"type\": \"mobile\",\n",
      "                \"type_config\": {},\n",
      "                \"value\": \"9709590075\",\n",
      "                \"value_config\": {}\n",
      "            },\n",
      "            {\n",
      "                \"_id\": \"3xyoEBz117508258490052\",\n",
      "                \"type\": \"email\",\n",
      "                \"type_config\": {},\n",
      "                \"value\": \"rajang797@gmail.com\",\n",
      "                \"value_config\": {}\n",
      "            },\n",
      "            {\n",
      "                \"_id\": \"92zAMWLI17508258490053\",\n",
      "                \"type\": \"sms\",\n",
      "                \"type_config\": {},\n",
      "                \"value\": \"9709590075\",\n",
      "                \"value_config\": {}\n",
      "            }\n",
      "        ],\n",
      "        \"show_brand_img\": 1,\n",
      "        \"enable_br\": 1,\n",
      "        \"br_img\": \"https://www.qrcodechimp.com/images/digitalCard/dbcv2/barand_logo_9.webp?v=1750825849004\"\n",
      "    },\n",
      "    {\n",
      "        \"component\": \"text_desc\",\n",
      "        \"title\": \"About Me\",\n",
      "        \"desc\": \"Description\",\n",
      "        \"title_config\": {\n",
      "            \"bold\": 1,\n",
      "            \"italic\": 0,\n",
      "            \"align\": \"center\",\n",
      "            \"lock\": \"unlock\"\n",
      "        },\n",
      "        \"desc_config\": {\n",
      "            \"bold\": 0,\n",
      "            \"italic\": 0,\n",
      "            \"align\": \"center\",\n",
      "            \"lock\": \"unlock\"\n",
      "        },\n",
      "        \"_id\": \"QUtpTNrB1750825849079L\",\n",
      "        \"card_enable\": 1\n",
      "    },\n",
      "    {\n",
      "        \"component\": \"contact\",\n",
      "        \"contact_title\": \"Contact Us\",\n",
      "        \"icon_img\": \"/images/digitalCard/contactus.png\",\n",
      "        \"floating_button_enable\": 1,\n",
      "        \"floating_button_label\": \"Add to Contact\",\n",
      "        \"ebusiness_card_enable\": 1,\n",
      "        \"contact_infos\": [\n",
      "            {\n",
      "                \"type\": \"number\",\n",
      "                \"title\": \"Call Us\",\n",
      "                \"label\": \"Mobile \",\n",
      "                \"number\": \"123 456 7890\",\n",
      "                \"_id\": \"60jggoha1750825849079N\"\n",
      "            },\n",
      "            {\n",
      "                \"type\": \"email\",\n",
      "                \"title\": \"Email\",\n",
      "                \"label\": \"Email \",\n",
      "                \"email\": \"contactme@domain.com\",\n",
      "                \"_id\": \"ziyf6bLt1750825849079O\"\n",
      "            },\n",
      "            {\n",
      "                \"type\": \"address\",\n",
      "                \"title\": \"Address\",\n",
      "                \"street\": \"Street\",\n",
      "                \"city\": \"City\",\n",
      "                \"country\": \"Country\",\n",
      "                \"state\": \"State\",\n",
      "                \"zip\": \"Zipcode\",\n",
      "                \"action_button_enable\": 1,\n",
      "                \"action_button_label\": \"Direction\",\n",
      "                \"action_button_link\": \"#\",\n",
      "                \"_id\": \"ndD3M75Y1750825849079P\"\n",
      "            }\n",
      "        ],\n",
      "        \"_id\": \"2p9TJT6q1750825849079M\",\n",
      "        \"card_enable\": 1\n",
      "    },\n",
      "    {\n",
      "        \"component\": \"images\",\n",
      "        \"header_enable\": 0,\n",
      "        \"title\": \"\",\n",
      "        \"desc\": \"\",\n",
      "        \"title_config\": {\n",
      "            \"bold\": 1,\n",
      "            \"italic\": 0,\n",
      "            \"align\": \"center\",\n",
      "            \"lock\": \"unlock\"\n",
      "        },\n",
      "        \"desc_config\": {\n",
      "            \"bold\": 0,\n",
      "            \"italic\": 0,\n",
      "            \"align\": \"center\",\n",
      "            \"lock\": \"unlock\"\n",
      "        },\n",
      "        \"view_type\": \"list\",\n",
      "        \"images\": [\n",
      "            \"/images/digitalCard/image_1.png\",\n",
      "            \"/images/digitalCard/image_2.png\",\n",
      "            \"/images/digitalCard/image_1.png\",\n",
      "            \"/images/digitalCard/image_2.png\"\n",
      "        ],\n",
      "        \"_id\": \"mhqSEqL11750825849079Q\",\n",
      "        \"card_enable\": 1\n",
      "    },\n",
      "    {\n",
      "        \"component\": \"social_link\",\n",
      "        \"header_enable\": 1,\n",
      "        \"title\": \"Social Links\",\n",
      "        \"desc\": \"Description\",\n",
      "        \"title_config\": {\n",
      "            \"bold\": 1,\n",
      "            \"italic\": 0,\n",
      "            \"align\": \"center\",\n",
      "            \"lock\": \"unlock\"\n",
      "        },\n",
      "        \"desc_config\": {\n",
      "            \"bold\": 0,\n",
      "            \"italic\": 0,\n",
      "            \"align\": \"center\",\n",
      "            \"lock\": \"unlock\"\n",
      "        },\n",
      "        \"links\": [\n",
      "            {\n",
      "                \"type\": \"facebook\",\n",
      "                \"url\": \"\",\n",
      "                \"title\": \"Facebook\",\n",
      "                \"subtitle\": \"Follow us on Facebook\",\n",
      "                \"subtitle_enable\": 1,\n",
      "                \"icon_img\": \"/images/digitalCard/fb_icon@72x.png\",\n",
      "                \"_id\": \"3uQie4Y91750825849080S\"\n",
      "            },\n",
      "            {\n",
      "                \"type\": \"instagram\",\n",
      "                \"url\": \"\",\n",
      "                \"title\": \"Instagram\",\n",
      "                \"subtitle\": \"Follow us on Instagram\",\n",
      "                \"subtitle_enable\": 0,\n",
      "                \"icon_img\": \"/images/digitalCard/insta_icon@72x.png\",\n",
      "                \"_id\": \"VL4W2Xnt1750825849080T\"\n",
      "            },\n",
      "            {\n",
      "                \"type\": \"twitter\",\n",
      "                \"url\": \"\",\n",
      "                \"title\": \"Twitter\",\n",
      "                \"subtitle\": \"Follow us on Twitter\",\n",
      "                \"subtitle_enable\": 0,\n",
      "                \"icon_img\": \"/images/digitalCard/tw_icon@72x.png\",\n",
      "                \"_id\": \"Jkyh7VyZ1750825849080U\"\n",
      "            }\n",
      "        ],\n",
      "        \"_id\": \"M8CTSg2A1750825849079R\",\n",
      "        \"card_enable\": 1\n",
      "    },\n",
      "    {\n",
      "        \"component\": \"web_links\",\n",
      "        \"header_enable\": 1,\n",
      "        \"title\": \"Web Links\",\n",
      "        \"desc\": \"Description\",\n",
      "        \"title_config\": {\n",
      "            \"bold\": 1,\n",
      "            \"italic\": 0,\n",
      "            \"align\": \"center\",\n",
      "            \"lock\": \"unlock\"\n",
      "        },\n",
      "        \"desc_config\": {\n",
      "            \"bold\": 0,\n",
      "            \"italic\": 0,\n",
      "            \"align\": \"center\",\n",
      "            \"lock\": \"unlock\"\n",
      "        },\n",
      "        \"links\": [\n",
      "            {\n",
      "                \"url\": \"https://www.mycoolbrand.com\",\n",
      "                \"title\": \"Title\",\n",
      "                \"subtitle\": \"Sub Title\",\n",
      "                \"subtitle_enable\": 1,\n",
      "                \"icon_img\": \"/images/digitalCard/weblink.png\",\n",
      "                \"_id\": \"f7ZG9Fxq1750825849080W\"\n",
      "            }\n",
      "        ],\n",
      "        \"_id\": \"EtyUyAYA1750825849080V\",\n",
      "        \"card_enable\": 1\n",
      "    },\n",
      "    {\n",
      "        \"component\": \"appointment\",\n",
      "        \"header_enable\": 1,\n",
      "        \"title\": \"Schedule Meeting\",\n",
      "        \"desc\": \"Schedule a meeting to discuss potential opportunities for collaboration\",\n",
      "        \"title_config\": {\n",
      "            \"bold\": 1,\n",
      "            \"italic\": 0,\n",
      "            \"align\": \"center\",\n",
      "            \"lock\": \"unlock\"\n",
      "        },\n",
      "        \"desc_config\": {\n",
      "            \"bold\": 0,\n",
      "            \"italic\": 0,\n",
      "            \"align\": \"center\",\n",
      "            \"lock\": \"unlock\"\n",
      "        },\n",
      "        \"appointments\": [\n",
      "            {\n",
      "                \"link\": \"\",\n",
      "                \"label\": \"Book on Calendly\"\n",
      "            },\n",
      "            {\n",
      "                \"link\": \"\",\n",
      "                \"label\": \"Add to Calendar\"\n",
      "            }\n",
      "        ],\n",
      "        \"card_enable\": 1,\n",
      "        \"_id\": \"sOOYMPOD1750825849080X\"\n",
      "    },\n",
      "    {\n",
      "        \"component\": \"form\",\n",
      "        \"card_label\": \"Collect Contacts\",\n",
      "        \"card_delete_disabled\": 1,\n",
      "        \"card_enable\": 0,\n",
      "        \"card_desc\": \"Enable this feature to collect your prospect's contact details\",\n",
      "        \"form_name\": \"Contact Collection\",\n",
      "        \"form_config\": [\n",
      "            {\n",
      "                \"header\": {\n",
      "                    \"title\": \"Hi, great to connect with you!\",\n",
      "                    \"desc\": \"Please provide the information below to proceed further\",\n",
      "                    \"header_enable\": 1\n",
      "                },\n",
      "                \"enable_header_img\": 1,\n",
      "                \"header_img\": \"/images/defaultImages/businesspage/b_brand_logo.png\",\n",
      "                \"form_fields\": [\n",
      "                    {\n",
      "                        \"type\": \"oneLine\",\n",
      "                        \"label\": \"Your Name\",\n",
      "                        \"required\": true,\n",
      "                        \"_id\": \"sg7CjRcf1750825849010D\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"type\": \"email\",\n",
      "                        \"label\": \"Your Email\",\n",
      "                        \"required\": true,\n",
      "                        \"_id\": \"7plFZYz31750825849010E\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"type\": \"tel\",\n",
      "                        \"label\": \"Your Phone\",\n",
      "                        \"required\": true,\n",
      "                        \"_id\": \"TSlYbths1750825849010F\"\n",
      "                    }\n",
      "                ],\n",
      "                \"button_label\": \"Submit\",\n",
      "                \"terms_label\": \"I agree to Terms and Privacy Policy\"\n",
      "            }\n",
      "        ],\n",
      "        \"view_config\": {\n",
      "            \"delay_time\": \"1\",\n",
      "            \"dismiss_form\": 1,\n",
      "            \"form_trigger\": \"delay\",\n",
      "            \"form_view\": \"full\",\n",
      "            \"view_type\": \"overlay\"\n",
      "        },\n",
      "        \"form_integration\": {},\n",
      "        \"_id\": \"rfwgQgSc1750825849080Y\"\n",
      "    }\n",
      "]'\n",
      "Generated text:\n",
      "\n",
      "You are a JSON generation system that formats user business card data into structured JSON.\n",
      "\n",
      "You will receive:\n",
      "1. User information (name, phone, email, company, etc.)\n",
      "2. A JSON template with placeholders or default data.\n",
      "\n",
      "Your task is:\n",
      "- Parse the user info and merge it into the template\n",
      "- Replace placeholders in JSON with actual user values\n",
      "- Ensure the JSON format remains valid and fully populated\n",
      "- Do not skip any components (e.g., profile, contact, web_links, etc.)\n",
      "- Return ONLY a JSON array as final output (no explanation or extra notes)\n",
      "\n",
      "User Info:\n",
      "Name: Rajan\n",
      "Designation: Mr\n",
      "Company: Tez Minds\n",
      "Phone: 9709590075\n",
      "Email: rajang797@gmail.com\n",
      "Website: https://www.mycoolbrand.com\n",
      "Socials: Facebook, Instagram, Twitter\n",
      "Description: Description\n",
      "Address: Street, City, State, Zipcode, Country\n",
      "Calendly: Link to book meetings\n",
      "\n",
      "JSON Template:\n",
      "(paste your full template JSON array here)\n",
      "\n",
      "Now output the updated JSON:\n",
      "[\n",
      "    {\n",
      "        \"component\": \"profile\",\n",
      "        \"card_background\": 0,\n",
      "        \"card_enable\": 1,\n",
      "        \"card_open\": 1,\n",
      "        \"_id\": \"uFpMGYHp1750825849079H\",\n",
      "        \"pr_img\": \"https://www.qrcodechimp.com/images/digitalCard/dbcv2/profile_1.webp?v=1750825849004\",\n",
      "        \"name\": \"Rajan \",\n",
      "        \"name_config\": {},\n",
      "        \"desc\": \"Mr\",\n",
      "        \"desc_config\": {},\n",
      "        \"company\": \"Tez Minds\",\n",
      "        \"contact_shortcut_enable\": 1,\n",
      "        \"enable_pr\": 1,\n",
      "        \"contact_shortcuts\": [\n",
      "            {\n",
      "                \"_id\": \"woMsSJ9x17508258490051\",\n",
      "                \"type\": \"mobile\",\n",
      "                \"type_config\": {},\n",
      "                \"value\": \"9709590075\",\n",
      "                \"value_config\": {}\n",
      "            },\n",
      "            {\n",
      "                \"_id\": \"3xyoEBz117508258490052\",\n",
      "                \"type\": \"email\",\n",
      "                \"type_config\": {},\n",
      "                \"value\": \"rajang797@gmail.com\",\n",
      "                \"value_config\": {}\n",
      "            },\n",
      "            {\n",
      "                \"_id\": \"92zAMWLI17508258490053\",\n",
      "                \"type\": \"sms\",\n",
      "                \"type_config\": {},\n",
      "                \"value\": \"9709590075\",\n",
      "                \"value_config\": {}\n",
      "            }\n",
      "        ],\n",
      "        \"show_brand_img\": 1,\n",
      "        \"enable_br\": 1,\n",
      "        \"br_img\": \"https://www.qrcodechimp.com/images/digitalCard/dbcv2/barand_logo_9.webp?v=1750825849004\"\n",
      "    },\n",
      "    {\n",
      "        \"component\": \"text_desc\",\n",
      "        \"title\": \"About Me\",\n",
      "        \"desc\": \"Description\",\n",
      "        \"title_config\": {\n",
      "            \"bold\": 1,\n",
      "            \"italic\": 0,\n",
      "            \"align\": \"center\",\n",
      "            \"lock\": \"unlock\"\n",
      "        },\n",
      "        \"desc_config\": {\n",
      "            \"bold\": 0,\n",
      "            \"italic\": 0,\n",
      "            \"align\": \"center\",\n",
      "            \"lock\": \"unlock\"\n",
      "        },\n",
      "        \"_id\": \"QUtpTNrB1750825849079L\",\n",
      "        \"card_enable\": 1\n",
      "    },\n",
      "    {\n",
      "        \"component\": \"contact\",\n",
      "        \"contact_title\": \"Contact Us\",\n",
      "        \"icon_img\": \"/images/digitalCard/contactus.png\",\n",
      "        \"floating_button_enable\": 1,\n",
      "        \"floating_button_label\": \"Add to Contact\",\n",
      "        \"ebusiness_card_enable\": 1,\n",
      "        \"contact_infos\": [\n",
      "            {\n",
      "                \"type\": \"number\",\n",
      "                \"title\": \"Call Us\",\n",
      "                \"label\": \"Mobile \",\n",
      "                \"number\": \"123 456 7890\",\n",
      "                \"_id\": \"60jggoha1750825849079N\"\n",
      "            },\n",
      "            {\n",
      "                \"type\": \"email\",\n",
      "                \"title\": \"Email\",\n",
      "                \"label\": \"Email \",\n",
      "                \"email\": \"contactme@domain.com\",\n",
      "                \"_id\": \"ziyf6bLt1750825849079O\"\n",
      "            },\n",
      "            {\n",
      "                \"type\": \"address\",\n",
      "                \"title\": \"Address\",\n",
      "                \"street\": \"Street\",\n",
      "                \"city\": \"City\",\n",
      "                \"country\": \"Country\",\n",
      "                \"state\": \"State\",\n",
      "                \"zip\": \"Zipcode\",\n",
      "                \"action_button_enable\": 1,\n",
      "                \"action_button_label\": \"Direction\",\n",
      "                \"action_button_link\": \"#\",\n",
      "                \"_id\": \"ndD3M75Y1750825849079P\"\n",
      "            }\n",
      "        ],\n",
      "        \"_id\": \"2p9TJT6q1750825849079M\",\n",
      "        \"card_enable\": 1\n",
      "    },\n",
      "    {\n",
      "        \"component\": \"images\",\n",
      "        \"header_enable\": 0,\n",
      "        \"title\": \"\",\n",
      "        \"desc\": \"\",\n",
      "        \"title_config\": {\n",
      "            \"bold\": 1,\n",
      "            \"italic\": 0,\n",
      "            \"align\": \"center\",\n",
      "            \"lock\": \"unlock\"\n",
      "        },\n",
      "        \"desc_config\": {\n",
      "            \"bold\": 0,\n",
      "            \"italic\": 0,\n",
      "            \"align\": \"center\",\n",
      "            \"lock\": \"unlock\"\n",
      "        },\n",
      "        \"view_type\": \"list\",\n",
      "        \"images\": [\n",
      "            \"/images/digitalCard/image_1.png\",\n",
      "            \"/images/digitalCard/image_2.png\",\n",
      "            \"/images/digitalCard/image_1.png\",\n",
      "            \"/images/digitalCard/image_2.png\"\n",
      "        ],\n",
      "        \"_id\": \"mhqSEqL11750825849079Q\",\n",
      "        \"card_enable\": 1\n",
      "    },\n",
      "    {\n",
      "        \"component\": \"social_link\",\n",
      "        \"header_enable\": 1,\n",
      "        \"title\": \"Social Links\",\n",
      "        \"desc\": \"Description\",\n",
      "        \"title_config\": {\n",
      "            \"bold\": 1,\n",
      "            \"italic\": 0,\n",
      "            \"align\": \"center\",\n",
      "            \"lock\": \"unlock\"\n",
      "        },\n",
      "        \"desc_config\": {\n",
      "            \"bold\": 0,\n",
      "            \"italic\": 0,\n",
      "            \"align\": \"center\",\n",
      "            \"lock\": \"unlock\"\n",
      "        },\n",
      "        \"links\": [\n",
      "            {\n",
      "                \"type\": \"facebook\",\n",
      "                \"url\": \"\",\n",
      "                \"title\": \"Facebook\",\n",
      "                \"subtitle\": \"Follow us on Facebook\",\n",
      "                \"subtitle_enable\": 1,\n",
      "                \"icon_img\": \"/images/digitalCard/fb_icon@72x.png\",\n",
      "                \"_id\": \"3uQie4Y91750825849080S\"\n",
      "            },\n",
      "            {\n",
      "                \"type\": \"instagram\",\n",
      "                \"url\": \"\",\n",
      "                \"title\": \"Instagram\",\n",
      "                \"subtitle\": \"Follow us on Instagram\",\n",
      "                \"subtitle_enable\": 0,\n",
      "                \"icon_img\": \"/images/digitalCard/insta_icon@72x.png\",\n",
      "                \"_id\": \"VL4W2Xnt1750825849080T\"\n",
      "            },\n",
      "            {\n",
      "                \"type\": \"twitter\",\n",
      "                \"url\": \"\",\n",
      "                \"title\": \"Twitter\",\n",
      "                \"subtitle\": \"Follow us on Twitter\",\n",
      "                \"subtitle_enable\": 0,\n",
      "                \"icon_img\": \"/images/digitalCard/tw_icon@72x.png\",\n",
      "                \"_id\": \"Jkyh7VyZ1750825849080U\"\n",
      "            }\n",
      "        ],\n",
      "        \"_id\": \"M8CTSg2A1750825849079R\",\n",
      "        \"card_enable\": 1\n",
      "    },\n",
      "    {\n",
      "        \"component\": \"web_links\",\n",
      "        \"header_enable\": 1,\n",
      "        \"title\": \"Web Links\",\n",
      "        \"desc\": \"Description\",\n",
      "        \"title_config\": {\n",
      "            \"bold\": 1,\n",
      "            \"italic\": 0,\n",
      "            \"align\": \"center\",\n",
      "            \"lock\": \"unlock\"\n",
      "        },\n",
      "        \"desc_config\": {\n",
      "            \"bold\": 0,\n",
      "            \"italic\": 0,\n",
      "            \"align\": \"center\",\n",
      "            \"lock\": \"unlock\"\n",
      "        },\n",
      "        \"links\": [\n",
      "            {\n",
      "                \"url\": \"https://www.mycoolbrand.com\",\n",
      "                \"title\": \"Title\",\n",
      "                \"subtitle\": \"Sub Title\",\n",
      "                \"subtitle_enable\": 1,\n",
      "                \"icon_img\": \"/images/digitalCard/weblink.png\",\n",
      "                \"_id\": \"f7ZG9Fxq1750825849080W\"\n",
      "            }\n",
      "        ],\n",
      "        \"_id\": \"EtyUyAYA1750825849080V\",\n",
      "        \"card_enable\": 1\n",
      "    },\n",
      "    {\n",
      "        \"component\": \"appointment\",\n",
      "        \"header_enable\": 1,\n",
      "        \"title\": \"Schedule Meeting\",\n",
      "        \"desc\": \"Schedule a meeting to discuss potential opportunities for collaboration\",\n",
      "        \"title_config\": {\n",
      "            \"bold\": 1,\n",
      "            \"italic\": 0,\n",
      "            \"align\": \"center\",\n",
      "            \"lock\": \"unlock\"\n",
      "        },\n",
      "        \"desc_config\": {\n",
      "            \"bold\": 0,\n",
      "            \"italic\": 0,\n",
      "            \"align\": \"center\",\n",
      "            \"lock\": \"unlock\"\n",
      "        },\n",
      "        \"appointments\": [\n",
      "            {\n",
      "                \"link\": \"\",\n",
      "                \"label\": \"Book on Calendly\"\n",
      "            },\n",
      "            {\n",
      "                \"link\": \"\",\n",
      "                \"label\": \"Add to Calendar\"\n",
      "            }\n",
      "        ],\n",
      "        \"card_enable\": 1,\n",
      "        \"_id\": \"sOOYMPOD1750825849080X\"\n",
      "    },\n",
      "    {\n",
      "        \"component\": \"form\",\n",
      "        \"card_label\": \"Collect Contacts\",\n",
      "        \"card_delete_disabled\": 1,\n",
      "        \"card_enable\": 0,\n",
      "        \"card_desc\": \"Enable this feature to collect your prospect's contact details\",\n",
      "        \"form_name\": \"Contact Collection\",\n",
      "        \"form_config\": [\n",
      "            {\n",
      "                \"header\": {\n",
      "                    \"title\": \"Hi, great to connect with you!\",\n",
      "                    \"desc\": \"Please provide the information below to proceed further\",\n",
      "                    \"header_enable\": 1\n",
      "                },\n",
      "                \"enable_header_img\": 1,\n",
      "                \"header_img\": \"/images/defaultImages/businesspage/b_brand_logo.png\",\n",
      "                \"form_fields\": [\n",
      "                    {\n",
      "                        \"type\": \"oneLine\",\n",
      "                        \"label\": \"Your Name\",\n",
      "                        \"required\": true,\n",
      "                        \"_id\": \"sg7CjRcf1750825849010D\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"type\": \"email\",\n",
      "                        \"label\": \"Your Email\",\n",
      "                        \"required\": true,\n",
      "                        \"_id\": \"7plFZYz31750825849010E\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"type\": \"tel\",\n",
      "                        \"label\": \"Your Phone\",\n",
      "                        \"required\": true,\n",
      "                        \"_id\": \"TSlYbths1750825849010F\"\n",
      "                    }\n",
      "                ],\n",
      "                \"button_label\": \"Submit\",\n",
      "                \"terms_label\": \"I agree to Terms and Privacy Policy\"\n",
      "            }\n",
      "        ],\n",
      "        \"view_config\": {\n",
      "            \"delay_time\": \"1\",\n",
      "            \"dismiss_form\": 1,\n",
      "            \"form_trigger\": \"delay\",\n",
      "            \"form_view\": \"full\",\n",
      "            \"view_type\": \"overlay\"\n",
      "        },\n",
      "        \"form_integration\": {},\n",
      "        \"_id\": \"rfwgQgSc1750825849080Y\"\n",
      "    }\n",
      "]\n",
      "\n",
      "Generating text with prompt: 'Describe the 'profile' component: '\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 351\u001b[39m\n\u001b[32m    349\u001b[39m prompt_related_to_data = \u001b[33m\"\u001b[39m\u001b[33mDescribe the \u001b[39m\u001b[33m'\u001b[39m\u001b[33mprofile\u001b[39m\u001b[33m'\u001b[39m\u001b[33m component: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    350\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mGenerating text with prompt: \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprompt_related_to_data\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m351\u001b[39m generated_output_related = \u001b[43mgenerate_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_related_to_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGenerated text:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mgenerated_output_related\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    354\u001b[39m prompt_related_to_data_qr = \u001b[33m\"\u001b[39m\u001b[33mExplain the purpose of \u001b[39m\u001b[33m'\u001b[39m\u001b[33mMyQR.png\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36mgenerate_text\u001b[39m\u001b[34m(prompt, model, tokenizer, max_new_tokens)\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Generate text\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     output = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_return_sequences\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Use the defined pad token ID\u001b[39;49;00m\n\u001b[32m     16\u001b[39m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Use the defined EOS token ID\u001b[39;49;00m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Decode the generated text\u001b[39;00m\n\u001b[32m     20\u001b[39m generated_text = tokenizer.decode(output[\u001b[32m0\u001b[39m], skip_special_tokens=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/leanPython/.venv/lib/python3.12/site-packages/peft/peft_model.py:1875\u001b[39m, in \u001b[36mPeftModelForCausalLM.generate\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1873\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._enable_peft_forward_hooks(*args, **kwargs):\n\u001b[32m   1874\u001b[39m         kwargs = {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.special_peft_forward_args}\n\u001b[32m-> \u001b[39m\u001b[32m1875\u001b[39m         outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbase_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1876\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1877\u001b[39m     outputs = \u001b[38;5;28mself\u001b[39m.base_model.generate(**kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/leanPython/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/leanPython/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:2597\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[39m\n\u001b[32m   2589\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   2590\u001b[39m         input_ids=input_ids,\n\u001b[32m   2591\u001b[39m         expand_size=generation_config.num_return_sequences,\n\u001b[32m   2592\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2593\u001b[39m         **model_kwargs,\n\u001b[32m   2594\u001b[39m     )\n\u001b[32m   2596\u001b[39m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2597\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2598\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2599\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2600\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2601\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2602\u001b[39m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m=\u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2603\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2604\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2605\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2607\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode.BEAM_SAMPLE, GenerationMode.BEAM_SEARCH):\n\u001b[32m   2608\u001b[39m     \u001b[38;5;66;03m# 11. interleave input_ids with `num_beams` additional sequences per batch\u001b[39;00m\n\u001b[32m   2609\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   2610\u001b[39m         input_ids=input_ids,\n\u001b[32m   2611\u001b[39m         expand_size=generation_config.num_beams,\n\u001b[32m   2612\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2613\u001b[39m         **model_kwargs,\n\u001b[32m   2614\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/leanPython/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:3560\u001b[39m, in \u001b[36mGenerationMixin._sample\u001b[39m\u001b[34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[39m\n\u001b[32m   3558\u001b[39m     is_prefill = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   3559\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3560\u001b[39m     outputs = \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   3562\u001b[39m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[32m   3563\u001b[39m model_kwargs = \u001b[38;5;28mself\u001b[39m._update_model_kwargs_for_generation(\n\u001b[32m   3564\u001b[39m     outputs,\n\u001b[32m   3565\u001b[39m     model_kwargs,\n\u001b[32m   3566\u001b[39m     is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   3567\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/leanPython/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/leanPython/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/leanPython/.venv/lib/python3.12/site-packages/transformers/utils/generic.py:969\u001b[39m, in \u001b[36mcan_return_tuple.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    966\u001b[39m     set_attribute_for_modules(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_is_top_level_module\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    968\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m969\u001b[39m     output = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    970\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_requested_to_return_tuple \u001b[38;5;129;01mor\u001b[39;00m (is_configured_to_return_tuple \u001b[38;5;129;01mand\u001b[39;00m is_top_level_module):\n\u001b[32m    971\u001b[39m         output = output.to_tuple()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/leanPython/.venv/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py:688\u001b[39m, in \u001b[36mLlamaForCausalLM.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, cache_position, logits_to_keep, **kwargs)\u001b[39m\n\u001b[32m    683\u001b[39m output_hidden_states = (\n\u001b[32m    684\u001b[39m     output_hidden_states \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.output_hidden_states\n\u001b[32m    685\u001b[39m )\n\u001b[32m    687\u001b[39m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m688\u001b[39m outputs: BaseModelOutputWithPast = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    689\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    690\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    691\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    692\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    693\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    694\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    695\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    696\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    697\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    698\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    699\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    701\u001b[39m hidden_states = outputs.last_hidden_state\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/leanPython/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/leanPython/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/leanPython/.venv/lib/python3.12/site-packages/transformers/utils/generic.py:969\u001b[39m, in \u001b[36mcan_return_tuple.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    966\u001b[39m     set_attribute_for_modules(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_is_top_level_module\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    968\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m969\u001b[39m     output = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    970\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_requested_to_return_tuple \u001b[38;5;129;01mor\u001b[39;00m (is_configured_to_return_tuple \u001b[38;5;129;01mand\u001b[39;00m is_top_level_module):\n\u001b[32m    971\u001b[39m         output = output.to_tuple()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/leanPython/.venv/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py:453\u001b[39m, in \u001b[36mLlamaModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, cache_position, **flash_attn_kwargs)\u001b[39m\n\u001b[32m    450\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states:\n\u001b[32m    451\u001b[39m     all_hidden_states += (hidden_states,)\n\u001b[32m--> \u001b[39m\u001b[32m453\u001b[39m layer_outputs = \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    454\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    455\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    456\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    458\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    459\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    460\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    462\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mflash_attn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    463\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    465\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    467\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/leanPython/.venv/lib/python3.12/site-packages/transformers/modeling_layers.py:48\u001b[39m, in \u001b[36mGradientCheckpointingLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.gradient_checkpointing \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.training:\n\u001b[32m     47\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m, **kwargs), *args)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/leanPython/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/leanPython/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/leanPython/.venv/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py:308\u001b[39m, in \u001b[36mLlamaDecoderLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[39m\n\u001b[32m    305\u001b[39m hidden_states = \u001b[38;5;28mself\u001b[39m.input_layernorm(hidden_states)\n\u001b[32m    307\u001b[39m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m308\u001b[39m hidden_states, self_attn_weights = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    309\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    310\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    313\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    315\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    319\u001b[39m hidden_states = residual + hidden_states\n\u001b[32m    321\u001b[39m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/leanPython/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/leanPython/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/leanPython/.venv/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py:276\u001b[39m, in \u001b[36mLlamaAttention.forward\u001b[39m\u001b[34m(self, hidden_states, position_embeddings, attention_mask, past_key_value, cache_position, **kwargs)\u001b[39m\n\u001b[32m    263\u001b[39m         attention_interface = ALL_ATTENTION_FUNCTIONS[\u001b[38;5;28mself\u001b[39m.config._attn_implementation]\n\u001b[32m    265\u001b[39m attn_output, attn_weights = attention_interface(\n\u001b[32m    266\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    267\u001b[39m     query_states,\n\u001b[32m   (...)\u001b[39m\u001b[32m    273\u001b[39m     **kwargs,\n\u001b[32m    274\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m276\u001b[39m attn_output = \u001b[43mattn_output\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m.contiguous()\n\u001b[32m    277\u001b[39m attn_output = \u001b[38;5;28mself\u001b[39m.o_proj(attn_output)\n\u001b[32m    278\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m attn_output, attn_weights\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Function to generate text\n",
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "def generate_text(prompt, model, tokenizer, max_new_tokens=2048):\n",
    "    # Encode the prompt\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    # Generate text\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            input_ids,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            num_return_sequences=1,\n",
    "            pad_token_id=tokenizer.pad_token_id, # Use the defined pad token ID\n",
    "            eos_token_id=tokenizer.eos_token_id # Use the defined EOS token ID\n",
    "        )\n",
    "\n",
    "    # Decode the generated text\n",
    "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "    return generated_text\n",
    "\n",
    "# Example usage:\n",
    "prompt = \"\"\"\n",
    "You are a JSON generation system that formats user business card data into structured JSON.\n",
    "\n",
    "You will receive:\n",
    "1. User information (name, phone, email, company, etc.)\n",
    "2. A JSON template with placeholders or default data.\n",
    "\n",
    "Your task is:\n",
    "- Parse the user info and merge it into the template\n",
    "- Replace placeholders in JSON with actual user values\n",
    "- Ensure the JSON format remains valid and fully populated\n",
    "- Do not skip any components (e.g., profile, contact, web_links, etc.)\n",
    "- Return ONLY a JSON array as final output (no explanation or extra notes)\n",
    "\n",
    "User Info:\n",
    "Name: Rajan\n",
    "Designation: Mr\n",
    "Company: Tez Minds\n",
    "Phone: 9709590075\n",
    "Email: rajang797@gmail.com\n",
    "Website: https://www.mycoolbrand.com\n",
    "Socials: Facebook, Instagram, Twitter\n",
    "Description: Description\n",
    "Address: Street, City, State, Zipcode, Country\n",
    "Calendly: Link to book meetings\n",
    "\n",
    "JSON Template:\n",
    "(paste your full template JSON array here)\n",
    "\n",
    "Now output the updated JSON:\n",
    "[\n",
    "    {\n",
    "        \"component\": \"profile\",\n",
    "        \"card_background\": 0,\n",
    "        \"card_enable\": 1,\n",
    "        \"card_open\": 1,\n",
    "        \"_id\": \"uFpMGYHp1750825849079H\",\n",
    "        \"pr_img\": \"https://www.qrcodechimp.com/images/digitalCard/dbcv2/profile_1.webp?v=1750825849004\",\n",
    "        \"name\": \"Rajan \",\n",
    "        \"name_config\": {},\n",
    "        \"desc\": \"Mr\",\n",
    "        \"desc_config\": {},\n",
    "        \"company\": \"Tez Minds\",\n",
    "        \"contact_shortcut_enable\": 1,\n",
    "        \"enable_pr\": 1,\n",
    "        \"contact_shortcuts\": [\n",
    "            {\n",
    "                \"_id\": \"woMsSJ9x17508258490051\",\n",
    "                \"type\": \"mobile\",\n",
    "                \"type_config\": {},\n",
    "                \"value\": \"9709590075\",\n",
    "                \"value_config\": {}\n",
    "            },\n",
    "            {\n",
    "                \"_id\": \"3xyoEBz117508258490052\",\n",
    "                \"type\": \"email\",\n",
    "                \"type_config\": {},\n",
    "                \"value\": \"rajang797@gmail.com\",\n",
    "                \"value_config\": {}\n",
    "            },\n",
    "            {\n",
    "                \"_id\": \"92zAMWLI17508258490053\",\n",
    "                \"type\": \"sms\",\n",
    "                \"type_config\": {},\n",
    "                \"value\": \"9709590075\",\n",
    "                \"value_config\": {}\n",
    "            }\n",
    "        ],\n",
    "        \"show_brand_img\": 1,\n",
    "        \"enable_br\": 1,\n",
    "        \"br_img\": \"https://www.qrcodechimp.com/images/digitalCard/dbcv2/barand_logo_9.webp?v=1750825849004\"\n",
    "    },\n",
    "    {\n",
    "        \"component\": \"text_desc\",\n",
    "        \"title\": \"About Me\",\n",
    "        \"desc\": \"Description\",\n",
    "        \"title_config\": {\n",
    "            \"bold\": 1,\n",
    "            \"italic\": 0,\n",
    "            \"align\": \"center\",\n",
    "            \"lock\": \"unlock\"\n",
    "        },\n",
    "        \"desc_config\": {\n",
    "            \"bold\": 0,\n",
    "            \"italic\": 0,\n",
    "            \"align\": \"center\",\n",
    "            \"lock\": \"unlock\"\n",
    "        },\n",
    "        \"_id\": \"QUtpTNrB1750825849079L\",\n",
    "        \"card_enable\": 1\n",
    "    },\n",
    "    {\n",
    "        \"component\": \"contact\",\n",
    "        \"contact_title\": \"Contact Us\",\n",
    "        \"icon_img\": \"/images/digitalCard/contactus.png\",\n",
    "        \"floating_button_enable\": 1,\n",
    "        \"floating_button_label\": \"Add to Contact\",\n",
    "        \"ebusiness_card_enable\": 1,\n",
    "        \"contact_infos\": [\n",
    "            {\n",
    "                \"type\": \"number\",\n",
    "                \"title\": \"Call Us\",\n",
    "                \"label\": \"Mobile \",\n",
    "                \"number\": \"123 456 7890\",\n",
    "                \"_id\": \"60jggoha1750825849079N\"\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"email\",\n",
    "                \"title\": \"Email\",\n",
    "                \"label\": \"Email \",\n",
    "                \"email\": \"contactme@domain.com\",\n",
    "                \"_id\": \"ziyf6bLt1750825849079O\"\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"address\",\n",
    "                \"title\": \"Address\",\n",
    "                \"street\": \"Street\",\n",
    "                \"city\": \"City\",\n",
    "                \"country\": \"Country\",\n",
    "                \"state\": \"State\",\n",
    "                \"zip\": \"Zipcode\",\n",
    "                \"action_button_enable\": 1,\n",
    "                \"action_button_label\": \"Direction\",\n",
    "                \"action_button_link\": \"#\",\n",
    "                \"_id\": \"ndD3M75Y1750825849079P\"\n",
    "            }\n",
    "        ],\n",
    "        \"_id\": \"2p9TJT6q1750825849079M\",\n",
    "        \"card_enable\": 1\n",
    "    },\n",
    "    {\n",
    "        \"component\": \"images\",\n",
    "        \"header_enable\": 0,\n",
    "        \"title\": \"\",\n",
    "        \"desc\": \"\",\n",
    "        \"title_config\": {\n",
    "            \"bold\": 1,\n",
    "            \"italic\": 0,\n",
    "            \"align\": \"center\",\n",
    "            \"lock\": \"unlock\"\n",
    "        },\n",
    "        \"desc_config\": {\n",
    "            \"bold\": 0,\n",
    "            \"italic\": 0,\n",
    "            \"align\": \"center\",\n",
    "            \"lock\": \"unlock\"\n",
    "        },\n",
    "        \"view_type\": \"list\",\n",
    "        \"images\": [\n",
    "            \"/images/digitalCard/image_1.png\",\n",
    "            \"/images/digitalCard/image_2.png\",\n",
    "            \"/images/digitalCard/image_1.png\",\n",
    "            \"/images/digitalCard/image_2.png\"\n",
    "        ],\n",
    "        \"_id\": \"mhqSEqL11750825849079Q\",\n",
    "        \"card_enable\": 1\n",
    "    },\n",
    "    {\n",
    "        \"component\": \"social_link\",\n",
    "        \"header_enable\": 1,\n",
    "        \"title\": \"Social Links\",\n",
    "        \"desc\": \"Description\",\n",
    "        \"title_config\": {\n",
    "            \"bold\": 1,\n",
    "            \"italic\": 0,\n",
    "            \"align\": \"center\",\n",
    "            \"lock\": \"unlock\"\n",
    "        },\n",
    "        \"desc_config\": {\n",
    "            \"bold\": 0,\n",
    "            \"italic\": 0,\n",
    "            \"align\": \"center\",\n",
    "            \"lock\": \"unlock\"\n",
    "        },\n",
    "        \"links\": [\n",
    "            {\n",
    "                \"type\": \"facebook\",\n",
    "                \"url\": \"\",\n",
    "                \"title\": \"Facebook\",\n",
    "                \"subtitle\": \"Follow us on Facebook\",\n",
    "                \"subtitle_enable\": 1,\n",
    "                \"icon_img\": \"/images/digitalCard/fb_icon@72x.png\",\n",
    "                \"_id\": \"3uQie4Y91750825849080S\"\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"instagram\",\n",
    "                \"url\": \"\",\n",
    "                \"title\": \"Instagram\",\n",
    "                \"subtitle\": \"Follow us on Instagram\",\n",
    "                \"subtitle_enable\": 0,\n",
    "                \"icon_img\": \"/images/digitalCard/insta_icon@72x.png\",\n",
    "                \"_id\": \"VL4W2Xnt1750825849080T\"\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"twitter\",\n",
    "                \"url\": \"\",\n",
    "                \"title\": \"Twitter\",\n",
    "                \"subtitle\": \"Follow us on Twitter\",\n",
    "                \"subtitle_enable\": 0,\n",
    "                \"icon_img\": \"/images/digitalCard/tw_icon@72x.png\",\n",
    "                \"_id\": \"Jkyh7VyZ1750825849080U\"\n",
    "            }\n",
    "        ],\n",
    "        \"_id\": \"M8CTSg2A1750825849079R\",\n",
    "        \"card_enable\": 1\n",
    "    },\n",
    "    {\n",
    "        \"component\": \"web_links\",\n",
    "        \"header_enable\": 1,\n",
    "        \"title\": \"Web Links\",\n",
    "        \"desc\": \"Description\",\n",
    "        \"title_config\": {\n",
    "            \"bold\": 1,\n",
    "            \"italic\": 0,\n",
    "            \"align\": \"center\",\n",
    "            \"lock\": \"unlock\"\n",
    "        },\n",
    "        \"desc_config\": {\n",
    "            \"bold\": 0,\n",
    "            \"italic\": 0,\n",
    "            \"align\": \"center\",\n",
    "            \"lock\": \"unlock\"\n",
    "        },\n",
    "        \"links\": [\n",
    "            {\n",
    "                \"url\": \"https://www.mycoolbrand.com\",\n",
    "                \"title\": \"Title\",\n",
    "                \"subtitle\": \"Sub Title\",\n",
    "                \"subtitle_enable\": 1,\n",
    "                \"icon_img\": \"/images/digitalCard/weblink.png\",\n",
    "                \"_id\": \"f7ZG9Fxq1750825849080W\"\n",
    "            }\n",
    "        ],\n",
    "        \"_id\": \"EtyUyAYA1750825849080V\",\n",
    "        \"card_enable\": 1\n",
    "    },\n",
    "    {\n",
    "        \"component\": \"appointment\",\n",
    "        \"header_enable\": 1,\n",
    "        \"title\": \"Schedule Meeting\",\n",
    "        \"desc\": \"Schedule a meeting to discuss potential opportunities for collaboration\",\n",
    "        \"title_config\": {\n",
    "            \"bold\": 1,\n",
    "            \"italic\": 0,\n",
    "            \"align\": \"center\",\n",
    "            \"lock\": \"unlock\"\n",
    "        },\n",
    "        \"desc_config\": {\n",
    "            \"bold\": 0,\n",
    "            \"italic\": 0,\n",
    "            \"align\": \"center\",\n",
    "            \"lock\": \"unlock\"\n",
    "        },\n",
    "        \"appointments\": [\n",
    "            {\n",
    "                \"link\": \"\",\n",
    "                \"label\": \"Book on Calendly\"\n",
    "            },\n",
    "            {\n",
    "                \"link\": \"\",\n",
    "                \"label\": \"Add to Calendar\"\n",
    "            }\n",
    "        ],\n",
    "        \"card_enable\": 1,\n",
    "        \"_id\": \"sOOYMPOD1750825849080X\"\n",
    "    },\n",
    "    {\n",
    "        \"component\": \"form\",\n",
    "        \"card_label\": \"Collect Contacts\",\n",
    "        \"card_delete_disabled\": 1,\n",
    "        \"card_enable\": 0,\n",
    "        \"card_desc\": \"Enable this feature to collect your prospect's contact details\",\n",
    "        \"form_name\": \"Contact Collection\",\n",
    "        \"form_config\": [\n",
    "            {\n",
    "                \"header\": {\n",
    "                    \"title\": \"Hi, great to connect with you!\",\n",
    "                    \"desc\": \"Please provide the information below to proceed further\",\n",
    "                    \"header_enable\": 1\n",
    "                },\n",
    "                \"enable_header_img\": 1,\n",
    "                \"header_img\": \"/images/defaultImages/businesspage/b_brand_logo.png\",\n",
    "                \"form_fields\": [\n",
    "                    {\n",
    "                        \"type\": \"oneLine\",\n",
    "                        \"label\": \"Your Name\",\n",
    "                        \"required\": true,\n",
    "                        \"_id\": \"sg7CjRcf1750825849010D\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"email\",\n",
    "                        \"label\": \"Your Email\",\n",
    "                        \"required\": true,\n",
    "                        \"_id\": \"7plFZYz31750825849010E\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"tel\",\n",
    "                        \"label\": \"Your Phone\",\n",
    "                        \"required\": true,\n",
    "                        \"_id\": \"TSlYbths1750825849010F\"\n",
    "                    }\n",
    "                ],\n",
    "                \"button_label\": \"Submit\",\n",
    "                \"terms_label\": \"I agree to Terms and Privacy Policy\"\n",
    "            }\n",
    "        ],\n",
    "        \"view_config\": {\n",
    "            \"delay_time\": \"1\",\n",
    "            \"dismiss_form\": 1,\n",
    "            \"form_trigger\": \"delay\",\n",
    "            \"form_view\": \"full\",\n",
    "            \"view_type\": \"overlay\"\n",
    "        },\n",
    "        \"form_integration\": {},\n",
    "        \"_id\": \"rfwgQgSc1750825849080Y\"\n",
    "    }\n",
    "]\"\"\"\n",
    "\n",
    "print(f\"\\nGenerating text with prompt: '{prompt}'\")\n",
    "generated_output = generate_text(prompt, model, tokenizer)\n",
    "print(f\"Generated text:\\n{generated_output}\")\n",
    "\n",
    "# Example using a prompt related to your data (e.g., a component or QR name)\n",
    "# Replace with a relevant prompt based on the 'component' or 'qr_name' data\n",
    "prompt_related_to_data = \"Describe the 'profile' component: \"\n",
    "print(f\"\\nGenerating text with prompt: '{prompt_related_to_data}'\")\n",
    "generated_output_related = generate_text(prompt_related_to_data, model, tokenizer)\n",
    "print(f\"Generated text:\\n{generated_output_related}\")\n",
    "\n",
    "prompt_related_to_data_qr = \"Explain the purpose of 'MyQR.png': \"\n",
    "print(f\"\\nGenerating text with prompt: '{prompt_related_to_data_qr}'\")\n",
    "generated_output_qr = generate_text(prompt_related_to_data_qr, model, tokenizer)\n",
    "print(f\"Generated text:\\n{generated_output_qr}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacaf087",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "\n",
    "# Your model and tokenizer are already loaded from the previous setup\n",
    "# No need to reload them - using the existing 'model' and 'tokenizer' variables\n",
    "\n",
    "user_question = \"\"\"Digital Business Card - CV Demo\n",
    "Rajan Gupta - Full Stack Developer\n",
    "Tez Minds\n",
    "Email: rajan@example.com | Phone: 9876543210\n",
    "Address: 123 Developer Lane, Code City, India\n",
    "About Me\n",
    "A passionate developer with 5+ years of experience in building scalable web and backend systems.\n",
    "Enthusiastic about Go, React, and cloud architecture.\n",
    "Skills\n",
    "Go, JavaScript, React, Node.js, MongoDB, REST APIs, Docker, Kubernetes\n",
    "Projects\n",
    "Parcel Management System\n",
    "A web app to track and manage parcel deliveries, with features like booking, invoice generation, and\n",
    "customer support.\n",
    "AI Prompt Platform\n",
    "Built a backend service that dynamically generates prompts using LLaMA for digital card generation\n",
    "based on user input.\n",
    "Education\n",
    "B.Tech in Computer Science - ABC University (2016-2020)\n",
    "Languages\n",
    "English, Hindi\n",
    "Social Links\n",
    "LinkedIn: https://linkedin.com/in/rajang\n",
    "GitHub: https://github.com/rajan-dev\n",
    "Twitter: @rajan_dev\"\"\"\n",
    "# JSON template as a separate variable for better readability\n",
    "json_template = {\n",
    "    \"template_id\": \"b_685bb94064ea9b78d567cade\",\n",
    "    \"qr_codes\": [\n",
    "        {\n",
    "            \"qr_name\": \"\",\n",
    "            \"short_url\": \"\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"component\": \"profile\",\n",
    "                    \"pr_img\": \"/images/digitalCard/dbcv2/profile_1.webp\",\n",
    "                    \"br_img\": \"/images/digitalCard/dbcv2/barand_logo_9.webp\",\n",
    "                    \"name\": \"Name\",\n",
    "                    \"desc\": \"Title\",\n",
    "                    \"company\": \"Company\",\n",
    "                    \"contact_shortcuts\": [\n",
    "                        {\"type\": \"mobile\", \"value\": \"0000000000\"},\n",
    "                        {\"type\": \"email\", \"value\": \"youremail@domain.com\"},\n",
    "                        {\"type\": \"sms\", \"value\": \"0000000000\"}\n",
    "                    ]\n",
    "                },\n",
    "                {\n",
    "                    \"component\": \"text_desc\",\n",
    "                    \"title\": \"About Me\",\n",
    "                    \"desc\": \"Description\",\n",
    "                    \"title_config\": {\"bold\": 1, \"italic\": 0, \"align\": \"center\", \"lock\": \"unlock\"},\n",
    "                    \"desc_config\": {\"bold\": 0, \"italic\": 0, \"align\": \"center\", \"lock\": \"unlock\"}\n",
    "                },\n",
    "                {\n",
    "                    \"component\": \"contact\",\n",
    "                    \"contact_title\": \"Contact Us\",\n",
    "                    \"icon_img\": \"/images/digitalCard/contactus.png\",\n",
    "                    \"floating_button_label\": \"Add to Contact\",\n",
    "                    \"ebusiness_card_enable\": 1,\n",
    "                    \"contact_infos\": [\n",
    "                        {\"type\": \"number\", \"title\": \"Call Us\", \"label\": \"Mobile \", \"number\": \"123 456 7890\"},\n",
    "                        {\"type\": \"email\", \"title\": \"Email\", \"label\": \"Email \", \"email\": \"contactme@domain.com\"},\n",
    "                        {\n",
    "                            \"type\": \"address\",\n",
    "                            \"title\": \"Address\",\n",
    "                            \"street\": \"Street\",\n",
    "                            \"city\": \"City\",\n",
    "                            \"country\": \"Country\",\n",
    "                            \"state\": \"State\",\n",
    "                            \"zip\": \"Zipcode\",\n",
    "                            \"action_button_label\": \"Direction\",\n",
    "                            \"action_button_link\": \"#\"\n",
    "                        }\n",
    "                    ]\n",
    "                },\n",
    "                {\n",
    "                    \"component\": \"images\",\n",
    "                    \"title\": \"\",\n",
    "                    \"desc\": \"\",\n",
    "                    \"title_config\": {\"bold\": 1, \"italic\": 0, \"align\": \"center\", \"lock\": \"unlock\"},\n",
    "                    \"desc_config\": {\"bold\": 0, \"italic\": 0, \"align\": \"center\", \"lock\": \"unlock\"},\n",
    "                    \"view_type\": \"list\",\n",
    "                    \"images\": [\n",
    "                        \"/images/digitalCard/image_1.png\",\n",
    "                        \"/images/digitalCard/image_2.png\",\n",
    "                        \"/images/digitalCard/image_1.png\",\n",
    "                        \"/images/digitalCard/image_2.png\"\n",
    "                    ]\n",
    "                },\n",
    "                {\n",
    "                    \"component\": \"social_link\",\n",
    "                    \"title\": \"Social Links\",\n",
    "                    \"desc\": \"Description\",\n",
    "                    \"title_config\": {\"bold\": 1, \"italic\": 0, \"align\": \"center\", \"lock\": \"unlock\"},\n",
    "                    \"desc_config\": {\"bold\": 0, \"italic\": 0, \"align\": \"center\", \"lock\": \"unlock\"},\n",
    "                    \"links\": [\n",
    "                        {\n",
    "                            \"type\": \"facebook\",\n",
    "                            \"url\": \"\",\n",
    "                            \"title\": \"Facebook\",\n",
    "                            \"subtitle\": \"Follow us on Facebook\",\n",
    "                            \"icon_img\": \"/images/digitalCard/fb_icon@72x.png\"\n",
    "                        },\n",
    "                        {\n",
    "                            \"type\": \"instagram\",\n",
    "                            \"url\": \"\",\n",
    "                            \"title\": \"Instagram\",\n",
    "                            \"subtitle\": \"Follow us on Instagram\",\n",
    "                            \"icon_img\": \"/images/digitalCard/insta_icon@72x.png\"\n",
    "                        },\n",
    "                        {\n",
    "                            \"type\": \"twitter\",\n",
    "                            \"url\": \"\",\n",
    "                            \"title\": \"Twitter\",\n",
    "                            \"subtitle\": \"Follow us on Twitter\",\n",
    "                            \"icon_img\": \"/images/digitalCard/tw_icon@72x.png\"\n",
    "                        }\n",
    "                    ]\n",
    "                },\n",
    "                {\n",
    "                    \"component\": \"web_links\",\n",
    "                    \"title\": \"Web Links\",\n",
    "                    \"desc\": \"Description\",\n",
    "                    \"title_config\": {\"bold\": 1, \"italic\": 0, \"align\": \"center\", \"lock\": \"unlock\"},\n",
    "                    \"desc_config\": {\"bold\": 0, \"italic\": 0, \"align\": \"center\", \"lock\": \"unlock\"},\n",
    "                    \"links\": [\n",
    "                        {\n",
    "                            \"url\": \"https://www.mycoolbrand.com\",\n",
    "                            \"title\": \"Title\",\n",
    "                            \"subtitle\": \"Sub Title\",\n",
    "                            \"icon_img\": \"/images/digitalCard/weblink.png\"\n",
    "                        }\n",
    "                    ]\n",
    "                },\n",
    "                {\n",
    "                    \"component\": \"appointment\",\n",
    "                    \"title\": \"Schedule Meeting\",\n",
    "                    \"desc\": \"Schedule a meeting to discuss potential opportunities for collaboration\",\n",
    "                    \"title_config\": {\"bold\": 1, \"italic\": 0, \"align\": \"center\", \"lock\": \"unlock\"},\n",
    "                    \"desc_config\": {\"bold\": 0, \"italic\": 0, \"align\": \"center\", \"lock\": \"unlock\"},\n",
    "                    \"appointments\": [\n",
    "                        {\"link\": \"\", \"label\": \"Book on Calendly\"},\n",
    "                        {\"link\": \"\", \"label\": \"Add to Calendar\"}\n",
    "                    ]\n",
    "                },\n",
    "                {\n",
    "                    \"component\": \"form\",\n",
    "                    \"card_label\": \"Collect Contacts\",\n",
    "                    \"card_delete_disabled\": 1,\n",
    "                    \"card_desc\": \"Enable this feature to collect your prospect's contact details\",\n",
    "                    \"form_name\": \"Contact Collection\",\n",
    "                    \"form_config\": [\n",
    "                        {\n",
    "                            \"header\": {\n",
    "                                \"title\": \"Hi, great to connect with you!\",\n",
    "                                \"desc\": \"Please provide the information below to proceed further\",\n",
    "                                \"header_enable\": 1\n",
    "                            },\n",
    "                            \"enable_header_img\": 1,\n",
    "                            \"header_img\": \"/images/defaultImages/businesspage/b_brand_logo.png\",\n",
    "                            \"form_fields\": [\n",
    "                                {\"type\": \"oneLine\", \"label\": \"Your Name\", \"required\": True, \"_id\": \"m5jMN0971750841633067D\"},\n",
    "                                {\"type\": \"email\", \"label\": \"Your Email\", \"required\": True, \"_id\": \"8gWDWfpY1750841633067E\"},\n",
    "                                {\"type\": \"tel\", \"label\": \"Your Phone\", \"required\": True, \"_id\": \"y4zLRmhk1750841633067F\"}\n",
    "                            ],\n",
    "                            \"button_label\": \"Submit\",\n",
    "                            \"terms_label\": \"I agree to Terms and Privacy Policy\"\n",
    "                        }\n",
    "                    ],\n",
    "                    \"view_config\": {\n",
    "                        \"delay_time\": \"1\",\n",
    "                        \"dismiss_form\": 1,\n",
    "                        \"form_trigger\": \"delay\",\n",
    "                        \"form_view\": \"full\",\n",
    "                        \"view_type\": \"overlay\"\n",
    "                    },\n",
    "                    \"form_integration\": []\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create the evaluation prompt\n",
    "eval_prompt = f\"\"\"Question: {user_question}\n",
    "\n",
    "check user in full detailed mannar and extract it all info and integrate all info this json template all field are required do not loss any fiels and donot add any field\n",
    "and i want all data integrated in this json formate strictly follow this json template\n",
    "\n",
    "{json.dumps(json_template, indent=2)}\"\"\"\n",
    "# Tokenize the prompt\n",
    "\n",
    "prompt_tokenized = tokenizer(eval_prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=2048)\n",
    "# Move to the same device as your model (should be auto-handled by device_map=\"auto\")\n",
    "prompt_tokenized = {k: v.to(model.device) for k, v in prompt_tokenized.items()}\n",
    "\n",
    "# Generate response\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output_tokens = model.generate(\n",
    "        **prompt_tokenized,\n",
    "        max_new_tokens=2048,\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9\n",
    "    )\n",
    "\n",
    "    # Decode only the new tokens (excluding the input prompt)\n",
    "    input_length = prompt_tokenized['input_ids'].shape[1]\n",
    "    generated_tokens = output_tokens[0][input_length:]\n",
    "    response = tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
    "\n",
    "    print(\"Generated Response:\")\n",
    "    print(response)\n",
    "\n",
    "    # Clear GPU cache\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681e5fcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
